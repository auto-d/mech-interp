{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b98cbc35",
      "metadata": {
        "id": "b98cbc35"
      },
      "source": [
        "# Overview\n",
        "\n",
        "This is a toy project for exploring mechanistic interpretability methods. We train a small neural network to detect the presence of an ascii face in a string, then draw some conclusions about the network internals."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7rQkWMfORIiy",
      "metadata": {
        "id": "7rQkWMfORIiy"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Our challenge to the toy model will be to classify a text string as either containing an ASCII face or not.\n",
        "\n",
        "Dataset generation and unicode escape sequence cleaning and padding out the data courtesy of GPT-5 (see https://chatgpt.com/c/690e24c8-a990-832d-9711-8f0cb77e94a3)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "D49xsFw3c1eW",
      "metadata": {
        "id": "D49xsFw3c1eW"
      },
      "source": [
        "Define dictionary of cute faces for our dataset. We'll interleave these among random characters from the same charset to present a challenge to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "rLtQdphPRO1N",
      "metadata": {
        "id": "rLtQdphPRO1N"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import string\n",
        "\n",
        "# Dictionary of horizontally-oriented ASCII faces (≈100 entries)\n",
        "ascii_faces = {\n",
        "    \"happy\": \"(^_^)\",\n",
        "    \"big_smile\": \"(^o^)\",\n",
        "    \"winky\": \"(^_~)\",\n",
        "    \"surprised\": \"(O_O)\",\n",
        "    \"disappointed\": \"(>_<)\",\n",
        "    \"cool\": \"(⌐■_■)\",\n",
        "    \"thinking\": \"(¬_¬)\",\n",
        "    \"angry\": \"(ಠ_ಠ)\",\n",
        "    \"lenny\": \"( ͡° ͜ʖ ͡°)\",\n",
        "    \"shrug\": \"¯\\\\_(ツ)_/¯\",\n",
        "    \"smirk\": \"(¬‿¬)\",\n",
        "    \"tired\": \"(‐_‐) zzz\",\n",
        "    \"love\": \"(♥_♥)\",\n",
        "    \"evil\": \"(>:) )\",\n",
        "    \"shock\": \"(°o°)\",\n",
        "    \"blush\": \"(^///^)\",\n",
        "    \"party\": \"(ﾉ◕ヮ◕)ﾉ*:･ﾟ✧\",\n",
        "    \"sunglasses\": \"(⌐■_■)\",\n",
        "    \"eyeroll\": \"(¬_ಠ)\",\n",
        "    \"confused\": \"(o_O)\",\n",
        "    \"awkward\": \"(._.)\",\n",
        "    \"victory\": \"＼(^o^)／\",\n",
        "    \"yay\": \"(^_^)v\",\n",
        "    \"hug\": \"(づ｡◕‿‿◕｡)づ\",\n",
        "    \"disgust\": \"(ಠ_ಠ ┌)\",\n",
        "    \"robot\": \"[¬º-°]¬\",\n",
        "    \"bang\": \"(ノಠ益ಠ)ノ彡┻━┻\",\n",
        "    \"wink_tongue\": \"(^<_<)\",\n",
        "    \"side_eye\": \"(>_> )\",\n",
        "    \"uhh\": \"(._. )\",\n",
        "    \"cry\": \"(;_;)\",\n",
        "    \"happy_tears\": \"(T_T)\",\n",
        "    \"cool_alt\": \"(▀̿Ĺ̯▀̿ ̿)\",\n",
        "    \"evil_grin\": \"(ʘ‿ʘ)\",\n",
        "    \"ache\": \"(x_x)\",\n",
        "    \"zombie\": \"(¬º-°)¬\",\n",
        "    \"joker\": \"(☭_☭)\",\n",
        "    \"pirate\": \"(☠_☠)\",\n",
        "    \"robot2\": \"(⌐■⁠_⁠■)\",\n",
        "    \"meh\": \"(-_-)\",\n",
        "    \"sleepy\": \"(‐ ‐)zzz\",\n",
        "    \"celebrate\": \"(ﾉ･ω･)ﾉﾞ\",\n",
        "    \"chuckle\": \"(＾ω＾)\",\n",
        "    \"grin\": \"(≧◡≦)\",\n",
        "    \"evil_smile\": \"(¬‿¬ )\",\n",
        "    \"sassy\": \"(¬_¬’)\",\n",
        "    \"tongue\": \"(:P)\",\n",
        "    \"groan\": \"(-｡-;)\",\n",
        "    \"hug2\": \"(づ￣ ³￣)づ\",\n",
        "    \"glasses\": \"(B^_^)B\",\n",
        "    \"victory2\": \"(^‿^✿)\",\n",
        "    \"cool3\": \"(⌐■_■)ﾉ\",\n",
        "    \"wut\": \"(°_°)\",\n",
        "    \"shock2\": \"(°◇°)\",\n",
        "    \"angry2\": \"(ಠ益ಠ)\",\n",
        "    \"eyeroll2\": \"(¬_¬)\",\n",
        "    \"blush2\": \"(^///^)\",\n",
        "    \"sad\": \"(T_T)\",\n",
        "    \"confused2\": \"(O_o)\",\n",
        "    \"surprised2\": \"(ʘ_ʘ)\",\n",
        "    \"wow\": \"(°д°)\",\n",
        "    \"smile2\": \"(^_−)☆\",\n",
        "    \"silly\": \"(-:)\",\n",
        "    \"yum\": \"(*≧ω≦)\",\n",
        "    \"facepalm\": \"(－‸ლ)\",\n",
        "    \"shush\": \"(☞ﾟヮﾟ)☞\",\n",
        "    \"raise_hand\": \"o(￣▽￣)o\",\n",
        "    \"highfive\": \"o/ (•‿•) \\\\o\",\n",
        "    \"zany\": \"(۞‿۞)\",\n",
        "    \"love2\": \"(♥‿♥)\",\n",
        "    \"grimace\": \"(>_<;)\",\n",
        "    \"smile3\": \"(◕‿◕)\",\n",
        "    \"mischief\": \"( ۞‿۞)\",\n",
        "    \"whistle\": \"(°▽°)ノ♪\",\n",
        "    \"cheer\": \"(ﾉ^_^)ﾉ\",\n",
        "    \"starstruck\": \"(✧ω✧)\",\n",
        "    \"cool5\": \"(⌐▨_▨)\",\n",
        "    \"ninja\": \"(ง •̀_•́)ง\",\n",
        "    \"worry\": \"(・_・;)\",\n",
        "    \"grumpy\": \"(－_－メ)\",\n",
        "    \"geek\": \"(ಠ‿↼)\",\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1RtnnMtIc-Vy",
      "metadata": {
        "id": "1RtnnMtIc-Vy"
      },
      "source": [
        "Do some ChatGPT-powered cleaning of the handful of escaped characters that would deny us a char-> int mapping later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3jZmLtOjTfgL",
      "metadata": {
        "id": "3jZmLtOjTfgL"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import unicodedata\n",
        "from pprint import pprint\n",
        "\n",
        "# Characters we always strip (zero-widths, joiners, BOM, etc.)\n",
        "ZERO_WIDTH = {\n",
        "    '\\u200b', '\\u200c', '\\u200d', '\\u200e', '\\u200f',  # ZW*, RTL/LTR marks\n",
        "    '\\u2060', '\\u2061', '\\u2062', '\\u2063', '\\u2064',  # word joiner, etc.\n",
        "    '\\ufeff',                                          # BOM\n",
        "}\n",
        "# Optional substitutions to normalize lookalikes (tweak to taste)\n",
        "SUBS = {\n",
        "    '—': '-',  # em dash -> hyphen\n",
        "    '–': '-',  # en dash -> hyphen\n",
        "    '－': '-',  # fullwidth hyphen-minus -> hyphen\n",
        "    '·': '•',  # middle dot -> bullet (or flip if you prefer)\n",
        "    '﹏': '_', # fullwidth low line alt -> underscore\n",
        "}\n",
        "\n",
        "# Regex for literal \\uXXXX sequences (when strings are double-escaped)\n",
        "_U_ESC_RE = re.compile(r'\\\\u([0-9a-fA-F]{4})')\n",
        "\n",
        "def _decode_u_escapes(s: str) -> str:\n",
        "    # Replace literal \\uXXXX with the actual codepoint\n",
        "    return _U_ESC_RE.sub(lambda m: chr(int(m.group(1), 16)), s)\n",
        "\n",
        "def canonicalize(s: str, normalize_form=\"NFC\") -> str:\n",
        "    o = s\n",
        "    # 1) turn any literal \\uXXXX into real chars (if present)\n",
        "    s = _decode_u_escapes(s)\n",
        "    # 2) Unicode normalize (NFC keeps composed glyphs; NFKC is more aggressive)\n",
        "    s = unicodedata.normalize(normalize_form, s)\n",
        "    # 3) strip zero-width/control-ish characters\n",
        "    s = ''.join(ch for ch in s if ch not in ZERO_WIDTH and not unicodedata.category(ch).startswith('C'))\n",
        "    # 4) apply substitutions\n",
        "    s = ''.join(SUBS.get(ch, ch) for ch in s)\n",
        "\n",
        "    if o != s:\n",
        "        print(f\"Converted escaped sequence '{o}' to '{s}'\")\n",
        "    return s\n",
        "\n",
        "def canonicalize_faces(dct: dict) -> dict:\n",
        "    return {k: canonicalize(v) for k, v in dct.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ybZo3-K_T7yQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybZo3-K_T7yQ",
        "outputId": "7ee811b3-08fb-43d3-c637-6b76bb0b63ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converted escaped sequence '(⌐■⁠_⁠■)' to '(⌐■_■)'\n",
            "Converted escaped sequence '(－‸ლ)' to '(-‸ლ)'\n",
            "Converted escaped sequence '(－_－メ)' to '(-_-メ)'\n",
            "Face character set:  ()*-./:;<>BOPT[\\]^_ovxz~¬¯°³ºĹʖʘ̯̀́̿͜͡ωд۞ಠงლ‐’•‸‿↼−≦≧⌐━┌┻▀■▨▽◇◕◡☆☞☠☭♥♪✧✿づツノメヮ・彡益／＼＾｡･ﾉﾞﾟ￣\n"
          ]
        }
      ],
      "source": [
        "# Strip out escaped sequences and swap in something that won't blow up my vectorization\n",
        "clean_faces = canonicalize_faces(ascii_faces)\n",
        "\n",
        "# Grab the charset of the\n",
        "face_charset = set()\n",
        "for face in clean_faces.values():\n",
        "    face_charset.update(face)\n",
        "face_charset = ''.join(sorted(face_charset))\n",
        "\n",
        "print(\"Face character set:\", face_charset)  # helpful for debug"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kmFiskFMdMtC",
      "metadata": {
        "id": "kmFiskFMdMtC"
      },
      "source": [
        "Define some ChatGPT-sourced routines for randomly sampling our cleaned face dict."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "IsuwjDHmVhAB",
      "metadata": {
        "id": "IsuwjDHmVhAB"
      },
      "outputs": [],
      "source": [
        "def get_random_face():\n",
        "    \"\"\"Return a random ASCII-face from the dictionary.\"\"\"\n",
        "    return random.choice(list(clean_faces.values()))\n",
        "\n",
        "def get_random_nonface(min_len=3, max_len=10):\n",
        "    \"\"\"\n",
        "    Generate a random string of characters drawn only from face_charset,\n",
        "    but arranged in a way that likely doesn’t look like a face.\n",
        "    \"\"\"\n",
        "    length = random.randint(min_len, max_len)\n",
        "    return ''.join(random.choice(face_charset) for _ in range(length))\n",
        "\n",
        "def sample_face(face_prob=0.5):\n",
        "    \"\"\"Sample either a face (positive) or a random non-face (negative).\"\"\"\n",
        "    if random.random() < face_prob:\n",
        "        return get_random_face(), True\n",
        "    else:\n",
        "        return get_random_nonface(), False\n",
        "\n",
        "def generate_dataset(n_samples, face_prob=0.5):\n",
        "    \"\"\"Generate a list of (text, label) pairs.\"\"\"\n",
        "    return [ sample_face(face_prob) for _ in range(n_samples) ]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hoeliXWddY6S",
      "metadata": {
        "id": "hoeliXWddY6S"
      },
      "source": [
        "Now randomly select a few faces and non-faces along with their label to validate the strategy. Then emit a dataset-worthy array of same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "AmwtRiMHRfEy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmwtRiMHRfEy",
        "outputId": "01adbb90-9655-4c60-8bba-78147ff14500"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(づ￣ ³￣)づ => FACE\n",
            "(°д°) => FACE\n",
            "￣☭\\z͜▽▀‸ => NON-FACE\n",
            "(¬º-°)¬ => FACE\n",
            "(°▽°)ノ♪ => FACE\n",
            "º■~ツ*ლ => NON-FACE\n",
            "／↼:･) => NON-FACE\n",
            "ʖ■◕♪°z[́♪◇ => NON-FACE\n",
            "‿‐°> => NON-FACE\n",
            "(♥_♥) => FACE\n"
          ]
        }
      ],
      "source": [
        "# Test our dataset generator\n",
        "for _ in range(10):\n",
        "    seq, label = sample_face(face_prob=0.5)\n",
        "    print(f\"{seq} => {'FACE' if label else 'NON-FACE'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "-GvtEbhjRgvL",
      "metadata": {
        "id": "-GvtEbhjRgvL"
      },
      "outputs": [],
      "source": [
        "# Generate a dataset of faces and non-faces\n",
        "seqs = []\n",
        "labels = []\n",
        "for _ in range(1000):\n",
        "  seq, label = sample_face(face_prob=0.5)\n",
        "  seqs.append(seq)\n",
        "  labels.append(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Mj_iP2TGdT_-",
      "metadata": {
        "id": "Mj_iP2TGdT_-"
      },
      "source": [
        "Finally, we need to get to a fixed-width for our input vector to the model we'll build. Sprinkle some GPT-5 sauce to define functions that map our characters into a relatively compact integer space (avoids super sparse values we'd otherwise get if we used the unicode value) and emit a padded variant of our dataset (fixed sequence length)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "id": "5V1HSjq5Sid_",
      "metadata": {
        "id": "5V1HSjq5Sid_"
      },
      "outputs": [],
      "source": [
        "def build_global_char_mapping(all_characters):\n",
        "    \"\"\"\n",
        "    Build integer mappings for every unique Unicode character in the dataset.\n",
        "\n",
        "    Parameters:\n",
        "        all_characters (Iterable[str]): A set or list of all unique characters\n",
        "                                        you expect to encounter (faces + non-faces).\n",
        "    Returns:\n",
        "        tuple(dict, dict): (char_to_int, int_to_char)\n",
        "    \"\"\"\n",
        "    # Sort for deterministic ordering (important for reproducibility)\n",
        "    sorted_chars = sorted(all_characters)\n",
        "\n",
        "    # Assign a unique integer ID to each character\n",
        "    char_to_int = {ch: idx for idx, ch in enumerate(sorted_chars)}\n",
        "    int_to_char = {idx: ch for ch, idx in char_to_int.items()}\n",
        "\n",
        "    return char_to_int, int_to_char\n",
        "\n",
        "def encode_strings(strings, char2int):\n",
        "    \"\"\"\n",
        "    Convert a list of strings into integer-based representations\n",
        "    using the provided char2int mapping.\n",
        "    Unknown characters are ignored or mapped to 0 if desired.\n",
        "    Returns a list of lists of integers.\n",
        "    \"\"\"\n",
        "    encoded = []\n",
        "    for s in strings:\n",
        "        encoded.append([char2int.get(ch, 0) for ch in s])\n",
        "    return encoded\n",
        "\n",
        "def decode_strings(encoded, int2char): \n",
        "\n",
        "    decoded = []\n",
        "    for a in encoded: \n",
        "        decoded.append(\"\".join([int2char.get(tok, \"?\") for tok in a]))\n",
        "    return decoded \n",
        "\n",
        "def random_pad_sequences(encoded_strings, pad_value=0):\n",
        "    \"\"\"\n",
        "    Randomly pad each integer sequence (left or right) so all have the same length.\n",
        "    pad_value is used for padding.\n",
        "    Returns a new list of equal-length sequences.\n",
        "    \"\"\"\n",
        "    # 1. Determine max length\n",
        "    max_len = max(len(seq) for seq in encoded_strings)\n",
        "    padded = []\n",
        "\n",
        "    for seq in encoded_strings:\n",
        "        pad_len = max_len - len(seq)\n",
        "        if pad_len == 0:\n",
        "            padded.append(seq)\n",
        "            continue\n",
        "\n",
        "        # Randomly choose left or right padding\n",
        "        if random.random() < 0.5:\n",
        "            # left pad\n",
        "            new_seq = [pad_value] * pad_len + seq\n",
        "        else:\n",
        "            # right pad\n",
        "            new_seq = seq + [pad_value] * pad_len\n",
        "\n",
        "        padded.append(new_seq)\n",
        "\n",
        "    return padded, max_len"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Hz9YkTUheNjA",
      "metadata": {
        "id": "Hz9YkTUheNjA"
      },
      "source": [
        "Build a mapping and test the encoding to see a string and it's integer value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b_JIQ6s2bAq0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_JIQ6s2bAq0",
        "outputId": "9cbb83bd-a602-4a76-ad84-a0065832be76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(¬_ಠ)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[1, 25, 19, 42, 2]]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "char2int, int2char = build_global_char_mapping(face_charset)\n",
        "\n",
        "test = seqs[1]\n",
        "print(test)\n",
        "encode_strings([test], char2int)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-s-Bqzb-edNV",
      "metadata": {
        "id": "-s-Bqzb-edNV"
      },
      "source": [
        "Now we can properly encode our strings and pad the result randomly to achieve fixed-width and positional diversity. We'll scale and recast these as floats to prepare for modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vO62-nL7aIqW",
      "metadata": {
        "id": "vO62-nL7aIqW"
      },
      "outputs": [],
      "source": [
        "encoded = encode_strings(seqs, char2int)\n",
        "padded, seq_len = random_pad_sequences(encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "D26vq9jre_Ag",
      "metadata": {
        "id": "D26vq9jre_Ag"
      },
      "outputs": [],
      "source": [
        "vocab_length = len(char2int)\n",
        "X = torch.tensor(padded, dtype=torch.int32)\n",
        "y = torch.tensor(labels, dtype=torch.float32) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "p7pfnZbBllTg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7pfnZbBllTg",
        "outputId": "7a74c2ae-7d96-49a0-acdd-b5c1e9b63a69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1000, 12])"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "CzgjHKqnfAev",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzgjHKqnfAev",
        "outputId": "c0a2aea6-4a2c-41f8-84d0-bf1bb20941dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0,  0, 86, 85, 35, 77, 18, 52, 32, 10, 77, 84],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  1, 25, 19, 42,  2],\n",
              "        [ 0,  0,  0,  0,  0,  1, 66, 88, 77, 88,  2, 66],\n",
              "        [ 0,  0,  0,  0,  6, 40, 34, 81, 83, 74, 59, 84],\n",
              "        [ 1,  0, 41, 49, 41,  2,  0,  0,  0,  0,  0,  0]], dtype=torch.int32)"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "tDBE780qfCkQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDBE780qfCkQ",
        "outputId": "8848b3f4-9b23-42fb-851f-5168537b2682"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 1., 1., 0., 1.])"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[0:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y85A_CpacQXJ",
      "metadata": {
        "id": "y85A_CpacQXJ"
      },
      "source": [
        "## Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7FUVHNOseqJv",
      "metadata": {
        "id": "7FUVHNOseqJv"
      },
      "source": [
        "We now need to build a model that will accept out weird sequence and try to classify it. We opt for a wickedly pared down variant of the transformer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "id": "SBmVRdtT34V4",
      "metadata": {
        "id": "SBmVRdtT34V4"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "p2rWZzi84FFW",
      "metadata": {
        "id": "p2rWZzi84FFW"
      },
      "outputs": [],
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    A toy torch module for self attention. Informed by Andrej Karpathy's mingpt project\n",
        "    (https://github.com/karpathy/minGPT) and a slightly embarassing conversation with\n",
        "    ChatGPT-5 (https://chatgpt.com/share/690e21fa-e718-8004-860a-45109a95c291)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_dim=10, scale=False):\n",
        "        \"\"\"\n",
        "        Input dimensions are typically sharded across heads in multi-head attention.\n",
        "        We are aiming for simplicity and avoid this, using just a single 'head' with\n",
        "        the full input dimension.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.Q = nn.Linear(n_dim, n_dim)\n",
        "        self.K = nn.Linear(n_dim, n_dim)\n",
        "        self.V = nn.Linear(n_dim, n_dim)\n",
        "\n",
        "        self.n_dim = n_dim\n",
        "        self.scale = scale\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        We accept input in the shape of seq length, model dimension.\n",
        "\n",
        "        Note we don't need any linear layers as output because we're only using a single\n",
        "        attention head. If we had more, we would need to map our heads back into the d_model\n",
        "        space with a linear layer.\n",
        "        \"\"\"\n",
        "\n",
        "        # Project our input into the query space (i.e. multiply by the query weights),\n",
        "        # do the same for the key vectors. Then apply our similarity operation (dot product\n",
        "        # by way of matmul) to yield an attention tensor.\n",
        "        q = self.Q(x)\n",
        "        k = self.K(x)\n",
        "        attn = torch.matmul(q, k.transpose(-2,-1))\n",
        "\n",
        "        # We optionally scale our attention values down to avoid them blasting off and saturating\n",
        "        # the softmax function (thereby destroying gradients during backprop). For tiny models,\n",
        "        # this is probably not an issue and so we allow omission to simplify the model.\n",
        "        if self.scale:\n",
        "            attn = attn / math.sqrt(self.n_dim)\n",
        "\n",
        "        # Now normalize our logits with softmax so we can scale the value vector based on the\n",
        "        # attention we are learning to pay to each respective token\n",
        "        attn = F.softmax(attn, dim=-1)\n",
        "\n",
        "        v = self.V(x)\n",
        "\n",
        "        out = torch.matmul(attn, v)\n",
        "\n",
        "        return out, attn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B1vWSfSafGpK",
      "metadata": {
        "id": "B1vWSfSafGpK"
      },
      "outputs": [],
      "source": [
        "class FaceClassifier(nn.Module):\n",
        "  \"\"\"\n",
        "  Dramatically oversized model to detect an ascii face in a string. However the sparsity it \n",
        "  probably encourages works for our introspection effort (maybe we can find some features associated\n",
        "  with specific faces)\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, vocab_size, seq_len, n_dim):\n",
        "      \"\"\"\n",
        "      Define a model that accepts a sequence and predicts whether it\n",
        "      contains a face. We don't support a batch dimension to simplify the matmuls\n",
        "      etc.\n",
        "      \"\"\"\n",
        "      super().__init__()\n",
        "\n",
        "      # Give the model a scratch pad, project each character into a richer space to learn some features\n",
        "      self.embedder = nn.Embedding(vocab_size, n_dim)\n",
        "      self.attn = SelfAttention(n_dim=n_dim, scale=True)\n",
        "      self.fc = nn.Linear(seq_len * n_dim, 1)\n",
        "      self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, X):\n",
        "      \"\"\"\n",
        "      Do a forward pass through the network, applying attention and emitting a class probability.\n",
        "      We accept a sequence of single values (representing the respective character), of\n",
        "      shape (seq, 1).\n",
        "      \"\"\"\n",
        "      # Learn a multidimensional (n_dim size) representation of the input characters, one for each character\n",
        "      # (n_seq, 1) -> (n_seq, n_dim)\n",
        "      X = self.embedder(X)\n",
        "\n",
        "      # (n_seq, n_dim) -> (n_seq, n_dim)\n",
        "      X, attn_map = self.attn(X)\n",
        "\n",
        "      # (n_seq * n_dim) -> (1)\n",
        "      X = self.fc(torch.flatten(X))\n",
        "\n",
        "      # (1) -> [0, 1]\n",
        "      X = self.sigmoid(X)\n",
        "\n",
        "      return X, attn_map "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "id": "af18aa07",
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate(model, X, y): \n",
        "    \"\"\"\n",
        "    Hasty validation of model performance against furnished data\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad(): \n",
        "        preds = []\n",
        "        for x, y_ in zip(X,y): \n",
        "            pred, _ = model(x)\n",
        "            preds.append(pred)\n",
        "        \n",
        "        preds = torch.tensor(preds)\n",
        "        mae = torch.abs(preds - y.numpy()).mean().item() \n",
        "    \n",
        "    return mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "id": "s_bNZNHuiApy",
      "metadata": {
        "id": "s_bNZNHuiApy"
      },
      "outputs": [],
      "source": [
        "def train(model, X_train, y_train, X_test, y_test, epochs=100):\n",
        "    \"\"\"\n",
        "    Train the face classifier\n",
        "    \"\"\"\n",
        "\n",
        "    # Use a fancy optimizer to help us converge, larger learning rates here result in a failure to \n",
        "    # stabilize at a low loss\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Binary cross-entropy loss calculator for our binary classification task\n",
        "    loss_fn = nn.BCELoss()\n",
        "\n",
        "    train_loss = []\n",
        "    val_loss = []\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Training mode, ensure gradients are tracked, etc.\n",
        "        model.train()\n",
        "        \n",
        "        epoch_loss = []\n",
        "        for x, y in zip(X_train, y_train):  \n",
        "\n",
        "            # Forward pass\n",
        "            out, attn = model(x)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = loss_fn(out, y.ravel())\n",
        "\n",
        "            # Backprop\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Apply those gradients to inch, bound, fly towards lower loss\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss.append(loss.item())\n",
        "        \n",
        "        train_loss.append(np.mean(epoch_loss))\n",
        "        val_loss.append(validate(model, X_test, y_test))\n",
        "        print(f\"Epoch loss: {train_loss[-1]:.7f} Validation loss: {val_loss[-1]:.7f}\") \n",
        "\n",
        "    return train_loss, val_loss\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cthtKjHIhtUz",
      "metadata": {
        "id": "cthtKjHIhtUz"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bk7q9_AzhvjO",
      "metadata": {
        "id": "bk7q9_AzhvjO"
      },
      "source": [
        "Now let's split up our data and train the model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "id": "H4nL30GQhmAd",
      "metadata": {
        "id": "H4nL30GQhmAd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "id": "baN7xKRohgIV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baN7xKRohgIV",
        "outputId": "f5e036ed-c28b-463a-b902-2594f7d824ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FaceClassifier(\n",
            "  (embedder): Embedding(90, 10)\n",
            "  (attn): SelfAttention(\n",
            "    (Q): Linear(in_features=10, out_features=10, bias=True)\n",
            "    (K): Linear(in_features=10, out_features=10, bias=True)\n",
            "    (V): Linear(in_features=10, out_features=10, bias=True)\n",
            "  )\n",
            "  (fc): Linear(in_features=120, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = FaceClassifier(vocab_size=len(face_charset), seq_len=seq_len, n_dim=10)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "id": "ouPzsDzio1Rg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "ouPzsDzio1Rg",
        "outputId": "22145d94-bb42-4f04-86ba-ed612d16a28e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/t0/vjz2r6l1155639x6cpfr8z3h0000gn/T/ipykernel_84292/3493466901.py:13: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  mae = torch.abs(preds - y.numpy()).mean().item()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch loss: 0.2329737 Validation loss: 0.0956468\n",
            "Epoch loss: 0.1207072 Validation loss: 0.0802939\n",
            "Epoch loss: 0.0895710 Validation loss: 0.0577825\n",
            "Epoch loss: 0.0562658 Validation loss: 0.0329470\n",
            "Epoch loss: 0.0316905 Validation loss: 0.0202102\n",
            "Epoch loss: 0.0165278 Validation loss: 0.0157777\n",
            "Epoch loss: 0.0077699 Validation loss: 0.0137616\n",
            "Epoch loss: 0.0037008 Validation loss: 0.0117326\n",
            "Epoch loss: 0.0014211 Validation loss: 0.0109986\n",
            "Epoch loss: 0.0007040 Validation loss: 0.0106654\n"
          ]
        }
      ],
      "source": [
        "train_loss, val_loss = train(model, X_train, y_train, X_test, y_test, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "id": "05d79358",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x12fd54cd0>]"
            ]
          },
          "execution_count": 276,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQUhJREFUeJzt3Qd4VGX+/v87M5NOEgghCSUQei9KL4oFxN4RsKBYF8vqsuqqu4r7W3ex7p+vgiDsKjYEu7uuDVEQJYA0kd4hlCQESCEhdfK/zhlSwARISHLOzLxf13WumXOm5GFGzM3TPgElJSUlAgAAsDGH1Q0AAAA4FQILAACwPQILAACwPQILAACwPQILAACwPQILAACwPQILAACwPQILAACwPZd8gNvt1r59+xQREaGAgACrmwMAAE6DsXdtdna2mjVrJofD4fuBxQgrCQkJVjcDAADUQHJyslq0aOH7gcXoWSn9A0dGRlrdHAAAcBqysrLMDofS3+M+H1hKh4GMsEJgAQDAu5zOdA4m3QIAANsjsAAAANsjsAAAANsjsAAAANsjsAAAANsjsAAAANsjsAAAANsjsAAAANsjsAAAANsjsAAAANsjsAAAANsjsAAAANsjsJxEZm6hXlu4TY9++Ev9fSMAAOA3CCwnUeR267mvNur95Xu053DuyZ4KAADqEIHlJBo3CFbvVo3M+9+uT63L7wEAAJwEgeUUhneJM2+/3ZB2qqcCAIA6QmA5heFd4s3bJdsPKvNoYV19DwAA4CQILKfQOiZc7WIbqMhdogWb6GUBAMAKBJZqDAvNYx4LAACWILBUI7As3HRABUXuuv5OAADACQgsp6FXi4ZqEhGs7Pwicy4LAACoXwSW0/mQHAEa1jnWvM+wEAAA9Y/AUu3lzakqKSmpy+8EAACcgMBymga1jVFYkFP7M/O0dm/W6b4MAADUAgLLaQoJdOrc9k3M+/PWp9TGZw8AAE4TgaUGw0LfsLwZAIB6RWCphgs6xcrpCNDGlGwlH6IYIgAA9YXAUg2NwoPU51gxRFYLAQBQfwgs1cSutwAA1D8CSzVddKwY4rKdh5SRW1AX3wkAADgBgaWaWjYOU8e4CBW7S/Q9xRABAKgXBJYaYFgIAID6RWA5w2KI+UXFtf2dAACAExBYaqB78yjFRQYrp6BYi7dRDBEAgLpGYKlxMURPLwvLmwEAqHsEljMthrg+VW43xRABAKhLBJYaGti2sRoEu5SWna81ezNr91sBAADHIbDUULDLqaEdKIYIAEB9ILCcAZY3AwBQPwgsZ+D8jp5iiJtTj2jXwZza+1YAAMBxCCxnICosUP1bR5v3WS0EAEDdIbDU0rDQN+tTa+P7AAAAlSCw1FJgWb7zkA7lUAwRAIC6QGA5Qy0ahalz00gZW7F8tzGtdr4VAABwHAJLra4WSqmNtwMAACcgsNSC4ce26f9hc7ryCimGCABAbSOw1IJuzSPVNCpERwuL9dPW9Np4SwAAUAGBpRYEBFAMEQCAukRgqe1iiBvSKIYIAEAtI7DUkgFtGisi2KX0I/lavSejtt4WAAAQWGpPkMuhoR1LiyGyiRwAALWJHpZaRDFEAADqBoGlFp3XMVYuR4C2ph3RjnSKIQIAUFsILLUoKjTQnMtiYBM5AABqD4GlljEsBABA7SOw1LJhx5Y3r9h1WAeP5Nf22wMA4JcILLWsecNQdW3mKYY4n2KIAABYF1imTp2qxMREhYSEqH///lq2bFmVz505c6bOOeccNWrUyDyGDRv2m+eXlJToqaeeUtOmTRUaGmo+Z8uWLfJWDAsBAGBxYJk7d64mTJigiRMnauXKlerZs6dGjBihtLS0Sp+/YMECjRkzRt9//72SkpKUkJCgiy66SHv37i17zvPPP6+XX35Z06dP19KlSxUeHm6+Z15enrw5sCzackBHCyiGCADAmQooMbo3qsHoUenbt6+mTJlinrvdbjOEPPDAA3rsscdO+fri4mKzp8V4/dixY83elWbNmumPf/yjHn74YfM5mZmZiouL06xZszR69OhTvmdWVpaioqLM10VGRspqxp9pyHPfa2/GUc0c26cswAAAgJr9/q5WD0tBQYFWrFhhDtmUvYHDYZ4bvSenIzc3V4WFhYqOjjbPd+zYoZSUlOPe02i8EYyqes/8/HzzD1nxsFsxxPJhoRSrmwMAgNerVmBJT083e0iM3o+KjHMjdJyOP/3pT2aPSmlAKX1ddd5z0qRJZqgpPYweHrspDSzzN6Sp2JiBCwAAvGOV0LPPPqs5c+bok08+MSfs1tTjjz9udh+VHsnJybKbfq2jFRni0sGcAq3afdjq5gAA4D+BJSYmRk6nU6mpxxf3M87j4+NP+toXX3zRDCzffPONevToUXa99HXVec/g4GBzrKviYTeBTofO7xRr3qcYIgAA9RhYgoKC1Lt3b82fP7/smjHp1jgfOHBgla8zVgH97W9/01dffaU+ffoc91jr1q3NYFLxPY05KcZqoZO9pzdgeTMAALXDVd0XGEuab731VjN49OvXT5MnT1ZOTo7GjRtnPm6s/GnevLk5z8Tw3HPPmXuszJ4929y7pXReSoMGDczDmKD60EMP6ZlnnlH79u3NAPPkk0+a81yuvvpqebOhHZoo0Bmg7ek5ZkHEdrENrG4SAAD+EVhGjRqlAwcOmCHECB+9evUye05KJ83u3r3bXDlUatq0aebqouuvv/649zH2cXn66afN+48++qgZeu6++25lZGRoyJAh5nueyTwXO4gICdTAtjH6YfMBc1iIwAIAQD3tw2JHdtuHpaK3l+zSk5+u1dktG+rjewdb3RwAAHx/HxZU3/DOnp6nVckZOpBNMUQAAGqCwFLH4qNC1KNFlIx+rPkbjl8JBQAATg+BpR57WVjeDABAzRBY6sHwrp7A8uPWdOUWFNXHjwQAwKcQWOpBx7gIJUSHKr/IrR82p9fHjwQAwKcQWOqrGGJnz669DAsBAFB9BJZ63vX2u42pKip219ePBQDAJxBY6knfxEZqGBaow7mFWrGLYogAAFQHgaWeuJwOXdCRYogAANQEgcWKYogbUuUDGwwDAFBvCCz16NwOTRTkcmjXwVxtSTtSnz8aAACvRmCpR+HBLg1u29i8z2ohAABOH4Glng3v4lne/M16tukHAOB0EVjq2bDOnom3vyRnKDUrr75/PAAAXonAUs9iI0PUK6GheX/+hrT6/vEAAHglAouVq4XWp1jx4wEA8DoEFgtcdCyw/LTtoHLyKYYIAMCpEFgs0C62gRIbh6nALIZ4wIomAADgVQgsVhVDLBsWYrUQAACnQmCxeHnzd5vSKIYIAMApEFgs0rtVI0WHBykjt1A/76QYIgAAJ0NgsYjTEaALOlEMEQCA00FgsUUxxBSKIQIAcBIEFgud0z5GwS6Hkg8d1abUbCubAgCArRFYLBQW5NKQdjHm/XnrWC0EAEBVCCy2GRYisAAAUBUCi8Uu7ByngABpzZ5MpWRSDBEAgMoQWCzWJCJYZx0rhkgvCwAAlSOw2GgTOXa9BQCgcgQWG81jSdqWruy8QqubAwCA7RBYbFIMsU1MuAqLS7SQYogAAPwGgcUmKIYIAEDVCCw2Cyzfb0xTYbHb6uYAAGArBBabOKtlIzUOD1JWXpGW7ThkdXMAALAVAouNiiFe2JliiAAAVIbAYtPlzSUlJVY3BwAA2yCw2IhRVygk0KG9GUe1fn+W1c0BAMA2CCw2Ehrk1Dntm5j32UQOAIByBBabYXkzAAC/RWCxmQs7xcoRIK3bl2UODQEAAAKL7TRuEKzerRqZ979dn2p1cwAAsAV6WGyIYSEAAI5HYLHx8uYl2w8q8yjFEAEAILDYUOuYcLMgYpG7RAs2pVndHAAALEdgsSmGhQAAKEdgsXlgWbjpgAqKKIYIAPBvBBab6tWioZpEBCs7v8icywIAgD8jsNiUwxGgYRRDBADARGDxgmGhbzdQDBEA4N8ILDY2qG2MwoKc2p+ZZ+58CwCAvyKw2FhIoFPnHiuG+A273gIA/BiBxeZY3gwAAIHF9i7oFCunI0Ab9mcp+VCu1c0BAMAS9LDYXKPwIPUpLYa4gWKIAAD/RGDxAgwLAQD8HYHFC1x0rBji0h2HlJlLMUQAgP8hsHiBlo3D1DEuQsXuEn1PMUQAgB8isHgJhoUAAP6MwOJlgWXBpjTlFxVb3RwAAOoVgcVLdG8epbjIYOUUFCtpG8UQAQD+hcDiVcUQPb0s89j1FgDgZ2oUWKZOnarExESFhISof//+WrZsWZXPXbduna677jrz+QEBAZo8efJvnvP000+bj1U8OnXqVJOm+U0xRLe7xOrmAABg38Ayd+5cTZgwQRMnTtTKlSvVs2dPjRgxQmlpaZU+Pzc3V23atNGzzz6r+HjP8tzKdO3aVfv37y87fvzxx+o2zecNbNtYDYJdSs3K1697M61uDgAA9g0s//znP3XXXXdp3Lhx6tKli6ZPn66wsDC9/vrrlT6/b9++euGFFzR69GgFBwdX+b4ul8sMNKVHTExMdZvm84JdTg3t4CmGyLAQAMCfVCuwFBQUaMWKFRo2bFj5Gzgc5nlSUtIZNWTLli1q1qyZ2Rtz0003affu3Wf0fr6K5c0AAH9UrcCSnp6u4uJixcV55lKUMs5TUlJq3AhjHsysWbP01Vdfadq0adqxY4fOOeccZWdnV/r8/Px8ZWVlHXf4i/M7eoohbkrN1u6DFEMEAPgHW6wSuuSSSzRy5Ej16NHDnA/zxRdfKCMjQ++//36lz580aZKioqLKjoSEBPmLqLBA9W8dbd7/Zn3NQyIAAD4bWIx5JU6nU6mpx1cNNs5PNqG2uho2bKgOHTpo69atlT7++OOPKzMzs+xITk6WP2FYCADgb6oVWIKCgtS7d2/Nnz+/7Jrb7TbPBw4cWGuNOnLkiLZt26amTZtW+rgxeTcyMvK4wx8Dy887D+lwToHVzQEAwH5DQsaS5pkzZ+rNN9/Uhg0bNH78eOXk5Jirhgxjx441e0AqTtRdvXq1eRj39+7da96v2Hvy8MMPa+HChdq5c6cWL16sa665xuzJGTNmTG39OX1Ki0Zh6tw0UsZWLN9trHw5OQAAvsRV3ReMGjVKBw4c0FNPPWVOtO3Vq5c5WbZ0Iq6xusdYOVRq3759Ouuss8rOX3zxRfMYOnSoFixYYF7bs2ePGU4OHjyoJk2aaMiQIVqyZIl5H1X3smzYn2Uub76udws+JgCATwsoKSnx+i1TjVVCxuRbYz6LvwwP/bonU1dM+VFhQU6tfHK4QgKdVjcJAIA6+/1ti1VCqL5uzSPVNCpEuQXFWrwtnY8QAODTCCxeyqi3RDFEAIC/ILD4RDHENIohAgB8GoHFiw1o01gRwS4dyM7X6j0ZVjcHAIA6Q2DxYkEuh4Z2pBgiAMD3EVi8HLveAgD8AYHFy53XMVYuR4C2ph3RjvQcq5sDAECdILB4uajQQHMui2EexRABAD6KwOIDGBYCAPg6AosPGHZsefOKXYd18Ei+1c0BAKDWEVh8QPOGoerajGKIAADfRWDxEQwLAQB8GYHFxwLLoi3pyisstro5AADUKgKLj+jSNNIcGjpaWKwft1AMEQDgWwgsPlQMkWEhAICvIrD4kNLAMn9jqordJVY3BwCAWkNg8SH9WkcrMsSl9CMFWp182OrmAABQawgsPiTQ6dD5nWLN+9+sT7W6OQAA1BoCi49hHgsAwBcRWHzM0A5NFOgM0PYDOdp24IjVzQEAoFYQWHxMREigBraNMe/PY1gIAOAjCCw+iGEhAICvIbD4oOGdPcubV+4+rAPZFEMEAHg/AosPio8KUY8WUSopkb7byGohAID3I7D4eC8L81gAAL6AwOKjhnctL4aYW1BkdXMAADgjBBYf1TEuQgnRocovcpuhBQAAb0Zg8eViiJ3jzfsMCwEAvB2BxQ+WN3+3MY1iiAAAr0Zg8WF9ExupYVigDuUUaMUuiiECALwXgcWHuZwOXdDRUwxx3voUq5sDAECNEVj8aNfbEmNjFgAAvBCBxced26GJglwO7TyYq61pFEMEAHgnAouPCw92aXDbxub9byiGCADwUgQWPzC8C8ubAQDejcDiB4Z19ky8XZ2cQW0hAIBXIrD4gdjIEF3Vq5l5/663Vuj95clWNwkAgGohsPiJF0f21HVntzA3kHv0wzWa+v1WVg0BALwGgcVPBDodenFkD917Xlvz/IWvN2nif9axAy4AwCsQWPysvtCjF3fS01d0UUCA9FbSLt0/e6XyCoutbhoAACdFYPFDtw1urVfGnKUgp0Nfrk3R2NeXKfNoodXNAgCgSgQWP3V5j2aadXtfRQS7tGzHIY16LUkpmXlWNwsAgEoRWPzYoLYxmnvPQMVGBGtjSraum7ZYW9OyrW4WAAC/QWDxc12aReqj8YPUpkm49mYc1fXTk6jsDACwHQILlBAdpg9/N0i9EhoqI7dQN/1rib5lG38AgI0QWGCKDg/S7Lv66/yOTZRX6Nbdby/XnGW7+XQAALZAYEGZsCCXZozto5G9W8hdIj328a96Zf4WNpgDAFiOwILfbDD3/PU9dP/57czzl+Zt1l8+XcsGcwAASxFYUOkGcw+P6Kj/d1VXc4O5d5fu1r3vrmCDOQCAZQgsqNLYgYmaeuPZ5gZzX69L1S3/XqrMXDaYAwDUPwILTurS7k311h39FBHi0s87D2vka4u1P/MonxoAoF4RWHBKA9o01ge/G6i4yGBtTj2ia19drC2pbDAHAKg/BBaclk7xkfr43sFq2yRc+zPzzA3mlu88xKcHAKgXBBactuYNQ80N5s5u2dAslnjTv5bq63UpfIIAgDpHYEG1NAoP0rt3DtCwzrHKL3Jr/DsrNHspG8wBAOoWgQXVFhrk1PSbe2t03wRzg7knPvlVk7/dzAZzAIA6Q2BBjbicDk26trt+f2F783zyt1v0xCdrVVTs5hMFANQ6AgvOaIO5CcM76Jmru5kbzL23bLfGv7uSDeYAALWOwIIzdvOAVpp209kKcjk0b32qORk3I7eATxYAUGsILKgVF3drqnfu6K/IEJdW7DpsLnvel8EGcwCA2kFgQa3p1zpaH/xukOIjQ7Q1zbPB3KYUNpgDAJw5AgtqVcf4CH187yC1i22glKw8jZy+WEu3H+RTBgDUf2CZOnWqEhMTFRISov79+2vZsmVVPnfdunW67rrrzOcbkzQnT558xu8Je2tmbjA3UH1aNVJWXpFueX2Zvlq73+pmAQD8KbDMnTtXEyZM0MSJE7Vy5Ur17NlTI0aMUFpaWqXPz83NVZs2bfTss88qPj6+Vt4T9tcwLEjv3Nlfw7vEqcDYYO7dlXp7yS6rmwUA8FIBJSUlJdV5gdH70bdvX02ZMsU8d7vdSkhI0AMPPKDHHnvspK81elAeeugh86it9zRkZWUpKipKmZmZioyMrM4fB3XM2Jflyc/WmUueDb+/oJ3+MLyD2dsGAPBvWdX4/V2tHpaCggKtWLFCw4YNK38Dh8M8T0pKqlFja/Ke+fn55h+y4gH7bjD3j2u66aFhng3mXv5uqx776Fc2mAMAVEu1Akt6erqKi4sVFxd33HXjPCWlZkXwavKekyZNMhNZ6WH0xsC+jN6Uh4Z10D+u6S5HgDR3ebLueXuFjhYUW900AICX8MpVQo8//rjZfVR6JCcnW90knIYb+7c0axAFuxyavzFNN/5riQ7nsMEcAKCWA0tMTIycTqdSU1OPu26cVzWhti7eMzg42BzrqnjAO1zUNV7v3tlfUaGBWrU7Q9dNX6w9h3OtbhYAwJcCS1BQkHr37q358+eXXTMmyBrnAwcOrFED6uI9YW99EqPNZc9No0K0/UCOrpu2WBtTmIcEAKjFISFj+fHMmTP15ptvasOGDRo/frxycnI0btw48/GxY8eaQzYVJ9WuXr3aPIz7e/fuNe9v3br1tN/TUjnpUvUWUuE0tI/zbDDXIa6BUrPyNXJ6kpawwRwAoLaWNRuM5ccvvPCCOSm2V69eevnll82lyYbzzjvPXL48a9Ys83znzp1q3br1b95j6NChWrBgwWm9p2XLmt1u6dX+UmCYNPB+qevVkjOw9t4fyswt1F1vLdeynYcU5HRo8uheurR7Uz4ZAPADWdX4/V2jwGI3dRZY0jZIM86TivI85xHNpP53S71vk0Ib1d7P8XN5hcV6cM4qfb0uVcb2LH+9sqvGDky0ulkAgDpGYKntIaHlb0jLZkg5x3beNXpcet0kDRgvNW5bqz/OXxW7S/TUZ2v17lLPBnP3nd9WD1/UkQ3mAMCHZdHDUgeK8qVfP5SWvCqlrj12MUDqeIk04F4pcYix4Uhd/GS/YXT2Tfluq16at9k8H9m7hf5xbXcFOr1y9T0A4BQILHXJGEHbsVBKelXa8nX59fge0sD7pK7XSq6gOm2Cr5uzbLee+ORXuUuk8zs20dSbzlZYkMvqZgEAahmBpb4c2CwtnSatfk8qOuq51iBe6neX1Od2KSy63pria75dn6r731upvEK3eiY01Bu39VV0OEEQAHwJgaW+5R6Slr8uLZspHTlWTsAVKvUa4xkuivHU0UH1rNh1WHe8+bMycgvVJiZcb97eTwnRYXyMAOAjCCxWKSqQ1n0sJU2RUn4tv95+hGe4qPW5zHOppq1p2br19Z+1N+OomkQE681x/dSlGTsbA4AvILBYzZjnsvNHzwTdTV8aFzzX47p5gku36yRXsNWt9BopmXm67Y1l2piSrYhgl14b21uD2sZY3SwAwBkisNjJwW3SEmOey7tS4bGaOQ3ipL7H5rmEN7a6hV4h82ih7n5ruZbu8Gww98qNZ2lE15rVrwIA2AOBxY6MeS4r35SWzpCy93muuUKknqM981yadLS6hV6xwdwf5q7Wl2tT5HQEaPKoXrqiZzOrmwUAqCECi50VF0rrPvXMc9m/uvx6u+HSwHulNuczz+UkiordevTDNfp41V45AqTnruuhkX0S6uGLAwDUNgKLNzDmuexOkpKmShv/Vz7PJbaLp8el+0gpMMTqVtqS212iP3+6Vu8t8+yK+7eruuoWtvIHAK9DYPE2h7ZLS6ZLq96RCnM818KbSH3vlPrcITVoYnULbbkr7l//u16zFu80z/9yWWfdeU4bq5sFAKgGAou3OppRPs8la4/nmjNY6nGDZ3VRbGerW2i70PLC15v06oJt5vkfh3fQAxey5w0AeAsCi7cz5rms/8wzXLRvZfn1thd4gkvbC5nnUsEr87eU1R+iaCIAeA8Ci68w5rkkLz02z+VzqcTtud6kk2eei9HzEhhqdSttYeYP2/X3LzaY98cNTtRTl3eh0jMA2ByBxRcd3iktfU1a+ZZUcMRzLayxZ56LcTSIlb97O2mnnvxsnXl/TL+W+vvV3eQwlhIBAGyJwOLL8jKllW97wkumZ5WMnEFSd2Oey71SXFf5s/eXJ+tPH60xO6euPau5nr++h1xOh9XNAgBUgsDiD4qLpI3/lZJelfYsK7/e5jxpwH1Su2GSwz9/UX+2eq8mvP+Lit0luqx7U00e3UuBhBYAsB0Ci79J/llaMtUzUbd0nktMB2nAeKnHaCnI/yocf70uRffPXqnC4hIN6xyrKTeerZBAp9XNAgBUQGDxVxm7y+e55Gd5roVGe2oW9btLivCv2jsLNqXpnrdXKL/IrXPax2jGLX0UGkRoAQC7ILD4u7wsT7FFo+hixi7PNUeg1HOUdOHTfrUR3eKt6brzreXKLShWv9bRev22vmoQ7LK6WQAAVS+w+OckB18XEukZDvr9KumGt6WEAZK70LOT7tR+0pr3PUum/cCgdjF66/Z+igh2admOQ7r5X0vNys8AAO9CYPFlDqfU5Urpjq+l27+R4rpJRw9JH98lzR4lZR7bTdfH9UmM1rt39VfDsECtTs7QjTOX6FBOgdXNAgBUA4HFX7TsL929QDr/L55l0Fu+lqYOkJa/blQTlK/r0aKh3rtrgGIaBGndviyNnpGktKw8q5sFADhNBBZ/4gyUhj4i3bNIatFXKsiWPv+D9OYV0kFPPR5f1rlppObcPVBxkcHanHpEo2Ys0b6Mo1Y3CwBwGggs/ii2k3T719LFz0qBYdKuH6Vpg6SfXvbs7+LD2sU20Pv3DFTzhqHakZ6jG15L0u6DuVY3CwBwCgQWf57fYkzMvTfJs9lcUZ4070np38OklLXyZa0ah+v93w1UYuMw7Tl81Awt2w4cK3cAALAlAou/a5Qo3fKpdOUUKThK2rdKmjFU+v4fUlG+fJXRw2L0tLSPbaCUrDyNei1JG1OO7V0DALAdAgukgADp7Fuk+5ZKHS+T3EXSwuek18717KLro2IjQzTn7gHq0jRS6UcKNHrGEv26J9PqZgEAKkFgQbnIptLod6WRs6TwJtKBjdK/h0tfPSEV5PjkJ9W4QbC5eqhnQkNl5BaaS55X7DpkdbMAACcgsOC3vS1dr5HuW+apQ6QST50iY1Lu9oU++WlFhQXqnTv6qV9itLLzi3TLv5cpadtBq5sFAKiAwILKhUVL174m3fShFNlCOrxTeutK6T8PSEczfO5TiwgJ1Kzb+5o1h4xt/G97Y5kWbj5gdbMAAMcQWHBy7Yd7VhL1vdNzbhRWfHWAtPELn/vkwoJcmjm2jy7sFGsWTLzrzeX6Zl2K1c0CABBYcNq1iS57SbrtCym6rZS9X5ozRvpgnHTEt3ohQgKdmnZzb13aPV4FxW6Nf3el/vvLPqubBQB+jx4WnL7EwdL4n6TBD0oBDmndxz5ZTDHI5dDLo8/SNWc1V7G7RA/OWaUPlidb3SwA8GsEFlRPYKg0/P9Jd8736WKKLqdDL43sqTH9EuQukR75cI3eXrLL6mYBgN8isKBmmp9deTHFn//tM8UUHY4A/eOa7rptUKJ5/uSna/WvRdutbhYA+CUCC2q3mOL/JvhUMcWAgABNvKKLxp/X1jx/5n8bNOW7LVY3CwD8DoEFZ87HiykaoeXRER01YXgH8/zFbzbrha83qsSH5u0AgN0RWFBL/yX5djFFI7T8/sL2euLSTub51O+36W+fbyC0AEA9IbCgdvl4McW7z22rv13V1bz/+k879OdP18ptzMoFANQpAgtqn48XU7xlYKKev76H+cecvXS3Hv7wFxUV+8ZEYwCwKwIL6o4PF1O8oU+CJo/qJacjQB+v3KsH56xWIaEFAOoMgQV1y4eLKV7Vq7mm3ni2Ap0B+t+v+zX+nRXKKyy2ulkA4JMILKgfPlpM8eJu8Zoxto+CXQ59uyFNd721XEcLCC0AUNsILKhfPlhM8fyOsXrjtr4KC3Jq0ZZ0s9LzkXzvX84NAHZCYEH988FiioPaxeit2/spItilpTsO6ZZ/L1Xm0UKrmwUAPoPAAuv4WDHFPonReveu/ooKDdSq3Rm6ceYSHcopsLpZAOATCCywlo8VU+zRoqHm3D1AjcODtG5flkbPSFJadp7VzQIAr0dggT34UDHFzk0jNfeegYqLDNbm1CMa9doS7cs4anWzAMCrEVhgHz5UTLFdbAO9f89ANW8Yqh3pObrhtSTtPphrdbMAwGsRWGA/PlJMsVXjcL3/u4FKbBymPYePmqFl24EjVjcLALwSgQX25CPFFI0eFqOnpX1sA6Vk5WnUa0namJJldbMAwOsQWOCFxRTPk36c7DVzW2IjQ8yJuMbclvQjBRo9Y4nW7s20ulkA4FUILPDCYoqF0rcTpbevlrL2yRs0bhCsOXcNUM+EhsrILdSYmUu0Ytdhq5sFAF6DwALvK6Z4xcueuS07FkrTBksb/ydvEBUWqHfu6Kd+idHKzisyN5f77y/eEbgAwGoEFnhfb0vvW6V7fpDie3j2bZlzo/T5H6QC+6/CiQgJ1Kzb++qc9jHKLSjWA++t0oS5q5Wdx664AHAyBBZ4p5j20p3fSoMe8Jwvf90zt2X/GtldWJBLr9/WV7+/oJ0cAdLHq/bq0pcXacWuQ1Y3DQBsi8AC7+UKli56RrrlE6lBvJS+SfrXhVLSVNtPyA10OjThoo7mBnMtGoUq+dBRjZyepH/O26yiYnu3HQCsQGCB92t7gacmUYdLpOIC6esnpHevl7JTZXd9E6P1xYPn6JqzmstdIr08f4tGvpakXQdzrG4aANgKgQW+ITxGGvOepwq0K0TaNt+z2dzmr2V3kSGB+v9G9dL/je6liBCXWTjx0v9bpA+WJ6vEC4tAAoBtAsvUqVOVmJiokJAQ9e/fX8uWLTvp8z/44AN16tTJfH737t31xRdfHPf4bbfdpoCAgOOOiy++uCZNg79PyO17p6cmkVFIMTddmn2D9MWjUqH9CxBe1au5vnzwHHMVUU5BsR75cI3un71KGblUfAaAageWuXPnasKECZo4caJWrlypnj17asSIEUpLS6v0+YsXL9aYMWN0xx13aNWqVbr66qvNY+3a43crNQLK/v37y4733nuPbwc1E9vZU/25/3jP+bLXpJnnS6nrbf+JtmgUpvfuHqBHRnSUyxGg//26X5f83yIt3pZuddMAwFIBJdXsczZ6VPr27aspU6aY5263WwkJCXrggQf02GOP/eb5o0aNUk5Ojj7//POyawMGDFCvXr00ffr0sh6WjIwMffrppzX6Q2RlZSkqKkqZmZmKjIys0XvAR22ZJ306Xso5IDmPTdLtd5enN8bmfknO0ENzV5vFE43m3n1uG/1xeEcFuRjJBeAbqvP7u1r/5ysoKNCKFSs0bNiw8jdwOMzzpKSkSl9jXK/4fIPRI3Pi8xcsWKDY2Fh17NhR48eP18GDB6tsR35+vvmHrHgAlWo/XBq/WGo3XCrOl758RHpvtJRj/x4LY1fczx8YojH9EmT8s+K1hdt17bSftDWNAooA/E+1Akt6erqKi4sVFxd33HXjPCUlpdLXGNdP9XxjOOitt97S/Pnz9dxzz2nhwoW65JJLzJ9VmUmTJpmJrPQweniAKjWIlW76QLr4OckZJG3+yjMhd+t8239o4cEuTbq2h6bf3FsNwwK1dm+WLn9lkd5ZsosJuQD8ii36lkePHq0rr7zSnJBrzG8xho9+/vlns9elMo8//rjZfVR6JCcn13ub4WWMMZUBv5Pu+l5q0kk6kiq9c6309Z+lonzZ3cXd4vX1Q+dqSLsY5RW69ZdP1+qut5br4BH7tx0A6j2wxMTEyOl0KjX1+P0tjPP4+PhKX2Ncr87zDW3atDF/1tatWyt9PDg42BzrqngApyW+m2cVkbGayJA0xbPZ3IHNtv8A4yJD9Nbt/fSXyzoryOnQtxvSNGLyIi3YVPmEdwDw28ASFBSk3r17m0M3pYxJt8b5wIEDK32Ncb3i8w3z5s2r8vmGPXv2mHNYmjZtWp3mAacnMNSzX8vo96TQaCnlV+m1c6Xlb8icLGJjDkeA7jynjT69b7A6xDVQ+pF83fbGz3r6P+uUV1j5ECoA+OWQkLGkeebMmXrzzTe1YcMGc4KssQpo3Lhx5uNjx441h2xKPfjgg/rqq6/00ksvaePGjXr66ae1fPly3X///ebjR44c0SOPPKIlS5Zo586dZri56qqr1K5dO3NyLlBnOl3qmZDb5jyp6Kj0+UPS3JulXPvX9OnSLFL/uX+IbhuUaJ7PWrxTV075URv2MwEdgG+qdmAxlim/+OKLeuqpp8ylyatXrzYDSenE2t27d5v7qJQaNGiQZs+erRkzZph7tnz44Yfm8uVu3bqZjxtDTGvWrDHnsHTo0MHcr8XoxVm0aJE59APUqcim0s2feJY7OwKljZ9L0wZL2xfa/oMPCXTq6Su76o1xfRXTIFibU4/oqik/6d8/7pDb2OcfAPx5HxY7Yh8W1Ip9q6WP7pQObjH+akiDH5TO/7PkCrL9B2wMDf3pwzWav9Ezn+Wc9jF6cWRPc94LAPjdPiyAT2vWS7pnoXT2rZJKpJ8mS69fJB3cJrszelj+dWsf/e3qbgoJdGjRlnRdPPkHfb2u8u0GAMDbEFiAioLCpStflm54WwppKO1bJU0/R1r1ju0n5Bo1uG4Z0MrcbK5rs0gdzi3UPW+v0OMfr1FuQZHVzQOAM0JgASrT5UrPhNzEc6TCHOmz+6QPx0lHD9v+82oXG6FP7h2se4a2MbefeW9Zsi5/+Uet2ZNhddMAoMYILEBVoppLYz+TLpwoOVzSuk+kaUOkXYtt/5kZ9YYev6Sz3r2jv+IjQ7Q9PUfXvrpYU7/fqmIm5ALwQgQW4KR/Q5zSOROkO76RottIWXukWZdJ3z0jFRfa/rMb1C5GXz10ji7tHq8id4le+HqTxsxcor0ZR61uGgBUC4EFOB3Ne0v3/CD1ukkqcUs/vCC9cYl0aIftP7+GYUGaeuPZeuH6HgoPcmrZjkPmhNz//LLP6qYBwGkjsACnKzhCuvpV6frXpeAoac/Pngm5v8y1/WdoTMgd2SdBXzx4jnolNFR2XpF+/94qTZi7Wtl59u8pAgACC1Bd3a6Txv8otRwoFWRLn9wtfXSXlJdp+8+yVeNwffC7gfr9he3lCJA+XrVXl768SCt22X93XwD+jcAC1ETDltKtn3s2lgtwSr++L00fIiUvs/3nGeh0aMLwDnr/noFq0ShUyYeOauT0JP1z3mYVFbutbh4AVIrAAtSU0yUNfVS6/StPgMnYLb1+sbTweclt/0KEfRKjzSGia89qLmPh0Mvzt+j66UnadTDH6qYBwG8QWIAzldBP+t2PUvcbpJJi6fu/e1YSGQHG5iJDAvXPUb308pizFBHi0urkDF36f4v0wfJk+UDVDgA+hMAC1IaQKOm6mdI1M6SgCGl3kmfPlrUfecXne2XPZvrqoXPVr3W0cgqK9ciHa3T/7FXKyC2wumkAYCKwALWp5yjpd4ukFn2l/Ezpw9ulT++V8rNt/zk3bxiq9+4aoEdGdJTLEaD//bpfF09epMXb0q1uGgAQWIBaF91aGveldO6jUoBDWv2uZ/nznhW2/7CdjgDdd347fXzvILWOCVdKVp5u+tdSTfpigwqKmJALwDr0sAB1wRkoXfBnz0qiyBbS4R2eys+L/ukVE3J7tGio//1+iMb0SzBrPr72w3Zd8+pP2pp2xOqmAfBTBBagLiUO9uzZ0uVqyV0kzf+r9NZVUuZe23/uYUEuTbq2h167pbcahQVq3b4sXf7KIr2zZBcTcgHUOwILUNdCG0kjZ0lXTZUCw6Wdi6Rpg6T1n8nsvrC5EV3jzQm557SPUV6hW3/5dK3uemu50o/kW900AH4koMQH1i5mZWUpKipKmZmZioyMtLo5QNUObpM+ukPat8pz3ri91HO01GOU1DDB1p+c212iNxbv1HNfblRBsVsxDYL1wsgeOr9jrNVNA+AHv78JLEB9KyqQFkySlkyTikqrJgdIrc+Reo6ROl/hqVtkUxv2Z+nBOau0OdUzn+W2QYn6w/AOigoNtLppALwMgQXwBnlZ0ob/SL/M8QwTlQoM84QWo+el9VDJ4ZTd5BUW69kvN2rW4p3meViQUyN7t9Btg1ubq4sA4HQQWABvY+yKu2autPo96dC28usRzaQeN3h6XmI7yW4WbErTpC82alOqZ5+ZgADpgo6xun1Iaw1q29isEg0AVSGwAN7KmFK2d4W0erZnl9y8jPLHmvbyBJfu10vhMbILYxpc0raDev2nHZq/Ma1sHnHHuAjdPiRRV/VqrpBA+/USAbAegQXwBUX50uavPUNGW772LIs2OFxS+4s8Q0YdLpZcwbKLHek5mvXTDn2wYo9yCzz7zUSHB+mm/i11y4BWio0MsbqJAGyEwAL4mpx0ae3H0i+zy1cYGUIaSt2u9fS8GOUAbDIEk3m0UO//nGzOcdmb4ZlYHOgM0BU9mmnc4Nbq3iLK6iYCsAECC+DL0jZKa+ZIa96XsipsQBfdxhNcjCXSjVrJDoqK3Zq3PtUcLvp55+Gy6/0So83houFd4s1yAAD8UxbLmgE/YGzxb6wuMoaM1v9HKswpf6zVYE946XKVFGKPvYnW7MnQ6z/u0Odr9qvI7Zno0qJRqLks+oa+CYoMYVk04G8ILIC/yT8ibfzcM1l3xw/GVFjPdVeI1OlyT3hpc57kdFndUqVm5entpF16d+kuHc4tNK+FG8ui+yTo1kGJLIsG/EgWPSyAH8vc4xku+uU9KX1z+fUGcVL3kVKvG6W4rrLDXi6frtprDheVbkJnTMG5sFOsbh/cWgNZFg34vCwCCwBzfbExQdcYMvr1A+noofIPJb77sSXSI6UGsZYvi/5pq2dZ9Hcb08qud4qPMIPLlb2asSwa8FEEFgC/LQewdZ6n12XTV5LbMxSjAKfU7kLPEumOl0qBoZZ+ctsOHNGbi3fqg+V7dLTQsyy68bFl0TezLBrwOQQWAFXLPSStM5ZIz5H2/Fx+PThK6nq1p+el5QBLl0hn5hZq7vLdenPxrt8sizZ20e3WnGXRgC8gsAA4PelbPb0uRlmAzOTy640SpR6jpZ6jPMulLVwW/fU6z7LoFbsqLItuHW0OFw3vEseyaMCLEVgAVI/bLe366dgS6U+lAs8kWFPCAM+QUddrpNCGln2yq5Mz9MZPO/Q/lkUDPoPAAqDmCnKljf/z7Kq7fYFU4vZcdwZLnS71DBm1vUByWrNvSkpmnt5eslPvLt2tjBOWRRt7uiRSLRrwGgQWALX0f5N9nhVGRhXpAxvKr4c38awwMnpe4ntYMt/laEGxPl2919yMbktaxWXRceYuugPbUC0asDsCC4DaXyKdssYzZGTs8ZKbXv5YTEfPvi5GOYCGrcpvoxIkV1C9LItetCXdnOeyYNOB45dFD2mtK3uyLBqwKwILgLpTXCht+86zq+6mL6Xi/CqeGCBFNvOEl4YtTwg0LaXI5pLDWatN25p2RLMW79BHK/Yevyx6QCvdPKClYiOoFg3YCYEFQP04elja+aN0eKeUsVs6vEvK2OW5LfIsR66SwyVFtTgh0CSWBxpjZ94aDjVl5BZozs/J5p4u+zPzypdF92xmri5iWTRgDwQWANYPIeUcOBZidpaHGOPcuJ+RXL55XVWMOkhGcKm0h6aVFNrolIGm0FwWnWLOc1m5O6Psen9jWfSQ1hrWmWXRgJUILADsX2k6e/9ve2XMMLNbytpbvjqpKkER5eGlsiGn4Ijjnr5q92G98dNOffFrebXohGijWnRr3dCnhSKoFg3UOwILAO8vJZC15/hemYqB5kjqqd8jNLqSQJOoNFec3trg1ts/pyrzqKeXp0GwS9f3bqGLu8XrrJYNFeyq3bk1ACpHYAHg+3vFGDvzloWYCoHGuM0rH/6pSkmDeKW74vXLkShtyGukPSVNlFESrjxnuFrEx6tjq+bq3jZBXVsnKCjE2hpLgK8isADwb3mZxw83nTj0VJhTrbcrUKCKAiPkCIlUUIOG5q2CI6WQqGO3kcffGsNRJz5mFJa0sD4T4O2BxVVvrQKA+mKEhfjunqOyCcFGAciMnceHmMw9KsnLVEFOhopyM+QsyFZIiWelU5AKFVR4SDKO7Bq2yVgVdVy4MQJNROWBx7yNOiEARUpBDQg98FsEFgD+xejlCG/sOZr3Pv4ho2j1scPgLirS1r379cuW3dqwc4927E1RQH6WIpSriICjilSuGrvy1CayWAlhxYoNyleEjprPkXHkHbtVifFm0tFDnqPGbXccCzkVwsxxtxUDUBXPMSYrOxxn9hkCFiCwAEAVHC6XOrRKMA+D212ijSnZStp+UEnbDuqzHQeVnVcklW+wq8gQl/q1bqyBPRprQJtodY5rIIcxBFUWYLKP3c88PtSceHvitZJiz8op43XGkVnTry3gJD07J4YcQg/sI6DE2Nfaj8bAAKC2FLtLtGF/lhlejBCzbMchHckvOu45DcMCzX1fjNpGA9o2VofYCDkc1ZzLYvxvujD3hFCTeUIAOjHkVBKITrX3Ta2EnkpCUFXzfGp5p2N4HybdAoAFiordWrcvq6wH5uedh5Rb4CkRUCo6PMjseTEDTJvGahfbQAH1MRnXCD1FeVWEntMMPMZtcUHttckYnjpZ4DE2DzSqgjsCPbfOIM9cIOPWvF7hftnzjHNXhfsVHzvheUZgYiK0pQgsAGADxk67v+7NNMPLku0HtXzn4bIaR6ViGgR7AkxbT4BpExNePwGmpgrzTjPwnOTxKutPWaBiyDFDzInB5sSwVFlwqux5FUKVcRjzj8yA5Cg/ys6dJ5wHVHLNeey89PUnPn6q9z3JexqPVdmWY4/XEQILANhQQZFba/ZklA0hrdh1WPlFx+/oGxdpBJjGZT0wrRqH2TvA1ERR/ql7ckqDjdGjU1zkGc4qvW/cmufHjor3zceOPcd8rMJ9Yx4QauBYoHGFSk/sUW0isACAF8gvKtbq3RlmeDF6YIx6R0aoqahpVEhZeDF6YRKiwyxrr9dzuysEnxPCTFnwOd2AVI3wZJSiKJ00bd53lx9l5xUfL6nkmvvYeUntvcZYvVYdRmD5S0qtfiUEFgDwQnmFxVq5+7CWmENIh7Qq+bAKi4//pdK8YagZXEon8RrnQI2UhZyqwlPpYxVCllFhvRYRWADABxwtKDaHjZK2p5sB5pfkjLLCjaVaRoeZ4aV0Dkx8VIhl7QWqi8ACAD4oJ79Iy3cdNoePjHkwxoReY2l1RYmNw9QuNkLNG4aoWcNQ82jeKNTsiWnSILj6S6qBOkRgAQA/kJ1XaK48MgPM9oNauzdTJ+SX4wQ6A8wemGZRngBTGmiaNQwpOw8PZj9R1B8CCwD4ocyjhVqdnKHkQ7nal3H02JGnvRlHlZKV95vemMpEhQZ6emXMo7yXpvRak4hgOemlQS2h+CEA+CEjbAzt0KTSx4ywkpadZ4aYvRme29Jjz2HPbVZekRl6jMPYwbcyLsexXppjAcbonakYaIzbBvTSoA7Q9wcAfsDoFWkaFWoevVtVPcS0P9PTI3NiD41xPyUzz5z0awQc4zh1L82JPTSe89iIEHppUG0EFgCAKSIk0Dw6xEVUu5em9Ly0h+ZUvTRxkaXzZo711jSilwYnR2ABANRaL41R/HG/GWBKe2dyK+2lMc6NoypG1evGDYLN28jQQLPXpuJR1bWIYBcroXwUgQUAUGuM+Svt4yLMo6pemgPZ+ScMO5X30BjXjd4ZYz6NcVSXUcXACC1RYZUEmpCqg47ncZdcTkctfAqwTWCZOnWqXnjhBaWkpKhnz5565ZVX1K9fvyqf/8EHH+jJJ5/Uzp071b59ez333HO69NJLyx4vKSnRxIkTNXPmTGVkZGjw4MGaNm2a+VwAgG/10hiTdo2jd6tGJ+2lOZxbqKwKQ0ylR+m1rLzjr+cVus3NW0vDTrKq7sE5WeAqDzEuM+QcF3DCqg4/QS7Cjq0Cy9y5czVhwgRNnz5d/fv31+TJkzVixAht2rRJsbGxv3n+4sWLNWbMGE2aNEmXX365Zs+erauvvlorV65Ut27dzOc8//zzevnll/Xmm2+qdevWZrgx3nP9+vUKCWHXRgDwx16amtRmKg80RScNOyee5xQUl4Ul4zjZcFVVQgOdigx1/ab3JiTQqSCnw5y7Y/TgBDk9ty5nwAnXPdeM+4GOAAUeOzduA0vvOxwKdAXIZdyWPvfY9YrP9cWl5wElRvdGNRghpW/fvpoyZYp57na7lZCQoAceeECPPfbYb54/atQo5eTk6PPPPy+7NmDAAPXq1csMPcaPb9asmf74xz/q4YcfNh/PzMxUXFycZs2apdGjR9fqOm4AAE5UWOxWdoVl3SeGmsrCT+lj2flFZs+OnQQEGBsFeoJPWaipGHoqhCMzQB0XeE4MTZ5rwS6H/nxZF+/Yh6WgoEArVqzQ448/XnbN4XBo2LBhSkpKqvQ1xnWjR6Yio/fk008/Ne/v2LHDHFoy3qOU0XgjGBmvrSyw5Ofnm0fFPzAAADVl/GKODg8yj+oy5uUcOSHsVByuMopaFhWXqNDtVmFRiYqM2+ISFRUbt24Vukvvl5jn5nMrXC8/d5ffL32923N+YmAyzo3K3wWeFtbKfxh1EViqo1qBJT09XcXFxWbvR0XG+caNGyt9jRFGKnu+cb308dJrVT3nRMbw0l//+tfqNB0AgDphDL+Yc1vCAi37hIuPBZeywHNcKDoWkopKTgg9lYejAvPWba7m8tz3PGZ221jIK1cJGT08FXttjB4WY1gKAAB/DU1Oh9OcL+OrqjWlOSYmRk6nU6mpqcddN87j4+MrfY1x/WTPL72tznsGBwebY10VDwAA4LuqFViCgoLUu3dvzZ8/v+yaMenWOB84cGClrzGuV3y+Yd68eWXPN1YFGcGk4nOMHpOlS5dW+Z4AAMC/VHtIyBiKufXWW9WnTx9z7xVjWbOxCmjcuHHm42PHjlXz5s3NeSaGBx98UEOHDtVLL72kyy67THPmzNHy5cs1Y8YM8/GAgAA99NBDeuaZZ8x9V0qXNRsrh4zlzwAAANUOLMYy5QMHDuipp54yJ8Uay5O/+uqrskmzu3fvNlcOlRo0aJC598pf/vIXPfHEE2YoMVYIle7BYnj00UfN0HP33XebG8cNGTLEfE/2YAEAADXah8WO2IcFAADf/v3NPsIAAMD2CCwAAMD2CCwAAMD2CCwAAMD2CCwAAMD2CCwAAMD2CCwAAMD2CCwAAMD2vLJa84lK974zNqABAADeofT39unsYesTgSU7O9u8TUhIsLopAACgBr/HjR1vfX5rfqNi9L59+xQREWEWU6zt9GcEoeTk5FNuG4y6x/dhL3wf9sN3Yi98HydnRBAjrBgFjyvWIfTZHhbjD9miRYs6/RlGWCGw2Affh73wfdgP34m98H1U7VQ9K6WYdAsAAGyPwAIAAGyPwHIKwcHBmjhxonkL6/F92Avfh/3wndgL30ft8YlJtwAAwLfRwwIAAGyPwAIAAGyPwAIAAGyPwAIAAGyPwHIKU6dOVWJiokJCQtS/f38tW7asfr4ZHGfSpEnq27evuZtxbGysrr76am3atIlPySaeffZZc5fphx56yOqm+K29e/fq5ptvVuPGjRUaGqru3btr+fLlVjfLLxUXF+vJJ59U69atze+ibdu2+tvf/nZa9XJQNQLLScydO1cTJkwwlzWvXLlSPXv21IgRI5SWlnayl6EOLFy4UPfdd5+WLFmiefPmqbCwUBdddJFycnL4vC32888/67XXXlOPHj2sborfOnz4sAYPHqzAwEB9+eWXWr9+vV566SU1atTI6qb5peeee07Tpk3TlClTtGHDBvP8+eef1yuvvGJ107way5pPwuhRMf5Vb/xHV1qzyKgr9MADD+ixxx6rr+8IlThw4IDZ02IEmXPPPZfPyCJHjhzR2WefrVdffVXPPPOMevXqpcmTJ/N91DPj/0c//fSTFi1axGdvA5dffrni4uL073//u+zaddddZ/a2vPPOO5a2zZvRw1KFgoICrVixQsOGDSv/sBwO8zwpKam+vh9UITMz07yNjo7mM7KQ0et12WWXHff3BPXvP//5j/r06aORI0eaQf6ss87SzJkz+SosMmjQIM2fP1+bN282z3/55Rf9+OOPuuSSS/hOzoBPFD+sC+np6eY4pJGSKzLON27caFm74OnpMuZKGF3g3bp14yOxyJw5c8yhUmNICNbavn27OQRhDGE/8cQT5nfy+9//XkFBQbr11lv5eizo8TKqNHfq1ElOp9P8XfL3v/9dN910E9/FGSCwwCv/Vb927VrzXyywRnJysh588EFzPpExIR3Wh3ijh+Uf//iHeW70sBh/R6ZPn05gscD777+vd999V7Nnz1bXrl21evVq8x9ZzZo14/s4AwSWKsTExJjJODU19bjrxnl8fPyZfOY4A/fff78+//xz/fDDD2rRogWfpUWM4VJj8rkxf6WU8a9I43sx5nzl5+ebf39QP5o2baouXbocd61z58766KOP+Aos8Mgjj5i9LKNHjzbPjRVbu3btMlc70uNVc8xhqYLRldq7d29zHLLiv2KM84EDB57BR46aMJYDGmHlk08+0XfffWcuF4R1LrzwQv3666/mvxxLD+Nf+EaXt3GfsFK/jOHRE5f5G/MnWrVqVc8tgSE3N9ec81iR8XfC+B2CmqOH5SSM8WAjDRv/I+7Xr5+5+sFYRjtu3Lgz+MhR02Ego3v1s88+M/diSUlJMa9HRUWZM+9Rv4zv4MT5Q+Hh4eYeIMwrqn9/+MMfzImexpDQDTfcYO4XNWPGDPNA/bviiivMOSstW7Y0h4RWrVqlf/7zn7r99tv5Os6EUa0ZVXvllVdKWrZsWRIUFFTSr1+/kiVLlvBxWcD4T7Wy44033uD7sImhQ4eWPPjgg1Y3w2/997//LenWrVtJcHBwSadOnUpmzJhhdZP8VlZWlvl3wfjdERISUtKmTZuSP//5zyX5+flWN82rsQ8LAACwPeawAAAA2yOwAAAA2yOwAAAA2yOwAAAA2yOwAAAA2yOwAAAA2yOwAAAA2yOwAAAA2yOwAAAA2yOwAAAA2yOwAAAA2yOwAAAA2d3/D25Hr4/s5iltAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt \n",
        "\n",
        "plt.plot(train_loss)\n",
        "plt.plot(val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9932f0f0",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "id": "1f95593a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ✧ツ━_づ━ งP┻ -> face NOT DETECTED\n",
            "  (▀̿Ĺ̯▀̿ ̿) -> face detected\n",
            "(✧ω✧)        -> face detected\n",
            "(o_O)        -> face detected\n",
            "      (-_-メ) -> face detected\n",
            "(ʘ‿ʘ)        -> face detected\n",
            "       (¬‿¬) -> face detected\n",
            "(・_・;)       -> face detected\n",
            "       °ω✿̿≧ -> face NOT DETECTED\n",
            "P(ﾉ▽／☆].*    -> face NOT DETECTED\n"
          ]
        }
      ],
      "source": [
        "decoded = decode_strings(X_test[0:10].numpy(), int2char)\n",
        "model.eval() \n",
        "for d,x in zip(decoded, X_test[0:10]): \n",
        "    pred, attn = model(x)\n",
        "    print(f\"{d} -> face {'detected' if pred > 0.5 else 'NOT DETECTED'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05696836",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1.], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "execution_count": 265,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74cc8769",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
