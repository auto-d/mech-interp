{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b98cbc35",
      "metadata": {
        "id": "b98cbc35"
      },
      "source": [
        "# Overview\n",
        "\n",
        "This is a toy project for exploring mechanistic interpretability methods. We train a small neural network to detect the presence of an ascii face in a string, then draw some conclusions about the network internals."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "Our challenge to the toy model will be to classify a text string as either containing an ASCII face or not.\n",
        "\n",
        "Dataset generation and unicode escape sequence cleaning and padding out the data courtesy of GPT-5 (see https://chatgpt.com/c/690e24c8-a990-832d-9711-8f0cb77e94a3)."
      ],
      "metadata": {
        "id": "7rQkWMfORIiy"
      },
      "id": "7rQkWMfORIiy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define dictionary of cute faces for our dataset. We'll interleave these among random characters from the same charset to present a challenge to the model."
      ],
      "metadata": {
        "id": "D49xsFw3c1eW"
      },
      "id": "D49xsFw3c1eW"
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import string\n",
        "\n",
        "# Dictionary of horizontally-oriented ASCII faces (≈100 entries)\n",
        "ascii_faces = {\n",
        "    \"happy\": \"(^_^)\",\n",
        "    \"big_smile\": \"(^o^)\",\n",
        "    \"winky\": \"(^_~)\",\n",
        "    \"surprised\": \"(O_O)\",\n",
        "    \"disappointed\": \"(>_<)\",\n",
        "    \"cool\": \"(⌐■_■)\",\n",
        "    \"thinking\": \"(¬_¬)\",\n",
        "    \"angry\": \"(ಠ_ಠ)\",\n",
        "    \"lenny\": \"( ͡° ͜ʖ ͡°)\",\n",
        "    \"shrug\": \"¯\\\\_(ツ)_/¯\",\n",
        "    \"smirk\": \"(¬‿¬)\",\n",
        "    \"tired\": \"(‐_‐) zzz\",\n",
        "    \"love\": \"(♥_♥)\",\n",
        "    \"evil\": \"(>:) )\",\n",
        "    \"shock\": \"(°o°)\",\n",
        "    \"blush\": \"(^///^)\",\n",
        "    \"party\": \"(ﾉ◕ヮ◕)ﾉ*:･ﾟ✧\",\n",
        "    \"sunglasses\": \"(⌐■_■)\",\n",
        "    \"eyeroll\": \"(¬_ಠ)\",\n",
        "    \"confused\": \"(o_O)\",\n",
        "    \"awkward\": \"(._.)\",\n",
        "    \"victory\": \"＼(^o^)／\",\n",
        "    \"yay\": \"(^_^)v\",\n",
        "    \"hug\": \"(づ｡◕‿‿◕｡)づ\",\n",
        "    \"disgust\": \"(ಠ_ಠ ┌)\",\n",
        "    \"robot\": \"[¬º-°]¬\",\n",
        "    \"bang\": \"(ノಠ益ಠ)ノ彡┻━┻\",\n",
        "    \"wink_tongue\": \"(^<_<)\",\n",
        "    \"side_eye\": \"(>_> )\",\n",
        "    \"uhh\": \"(._. )\",\n",
        "    \"cry\": \"(;_;)\",\n",
        "    \"happy_tears\": \"(T_T)\",\n",
        "    \"cool_alt\": \"(▀̿Ĺ̯▀̿ ̿)\",\n",
        "    \"evil_grin\": \"(ʘ‿ʘ)\",\n",
        "    \"ache\": \"(x_x)\",\n",
        "    \"zombie\": \"(¬º-°)¬\",\n",
        "    \"joker\": \"(☭_☭)\",\n",
        "    \"pirate\": \"(☠_☠)\",\n",
        "    \"robot2\": \"(⌐■⁠_⁠■)\",\n",
        "    \"meh\": \"(-_-)\",\n",
        "    \"sleepy\": \"(‐ ‐)zzz\",\n",
        "    \"celebrate\": \"(ﾉ･ω･)ﾉﾞ\",\n",
        "    \"chuckle\": \"(＾ω＾)\",\n",
        "    \"grin\": \"(≧◡≦)\",\n",
        "    \"evil_smile\": \"(¬‿¬ )\",\n",
        "    \"sassy\": \"(¬_¬’)\",\n",
        "    \"tongue\": \"(:P)\",\n",
        "    \"groan\": \"(-｡-;)\",\n",
        "    \"hug2\": \"(づ￣ ³￣)づ\",\n",
        "    \"glasses\": \"(B^_^)B\",\n",
        "    \"victory2\": \"(^‿^✿)\",\n",
        "    \"cool3\": \"(⌐■_■)ﾉ\",\n",
        "    \"wut\": \"(°_°)\",\n",
        "    \"shock2\": \"(°◇°)\",\n",
        "    \"angry2\": \"(ಠ益ಠ)\",\n",
        "    \"eyeroll2\": \"(¬_¬)\",\n",
        "    \"blush2\": \"(^///^)\",\n",
        "    \"sad\": \"(T_T)\",\n",
        "    \"confused2\": \"(O_o)\",\n",
        "    \"surprised2\": \"(ʘ_ʘ)\",\n",
        "    \"wow\": \"(°д°)\",\n",
        "    \"smile2\": \"(^_−)☆\",\n",
        "    \"silly\": \"(-:)\",\n",
        "    \"yum\": \"(*≧ω≦)\",\n",
        "    \"facepalm\": \"(－‸ლ)\",\n",
        "    \"shush\": \"(☞ﾟヮﾟ)☞\",\n",
        "    \"raise_hand\": \"o(￣▽￣)o\",\n",
        "    \"highfive\": \"o/ (•‿•) \\\\o\",\n",
        "    \"zany\": \"(۞‿۞)\",\n",
        "    \"love2\": \"(♥‿♥)\",\n",
        "    \"grimace\": \"(>_<;)\",\n",
        "    \"smile3\": \"(◕‿◕)\",\n",
        "    \"mischief\": \"( ۞‿۞)\",\n",
        "    \"whistle\": \"(°▽°)ノ♪\",\n",
        "    \"cheer\": \"(ﾉ^_^)ﾉ\",\n",
        "    \"starstruck\": \"(✧ω✧)\",\n",
        "    \"cool5\": \"(⌐▨_▨)\",\n",
        "    \"ninja\": \"(ง •̀_•́)ง\",\n",
        "    \"worry\": \"(・_・;)\",\n",
        "    \"grumpy\": \"(－_－メ)\",\n",
        "    \"geek\": \"(ಠ‿↼)\",\n",
        "}"
      ],
      "metadata": {
        "id": "rLtQdphPRO1N"
      },
      "id": "rLtQdphPRO1N",
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do some ChatGPT-powered cleaning of the handful of escaped characters that would deny us a char-> int mapping later."
      ],
      "metadata": {
        "id": "1RtnnMtIc-Vy"
      },
      "id": "1RtnnMtIc-Vy"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "from pprint import pprint\n",
        "\n",
        "# Characters we always strip (zero-widths, joiners, BOM, etc.)\n",
        "ZERO_WIDTH = {\n",
        "    '\\u200b', '\\u200c', '\\u200d', '\\u200e', '\\u200f',  # ZW*, RTL/LTR marks\n",
        "    '\\u2060', '\\u2061', '\\u2062', '\\u2063', '\\u2064',  # word joiner, etc.\n",
        "    '\\ufeff',                                          # BOM\n",
        "}\n",
        "# Optional substitutions to normalize lookalikes (tweak to taste)\n",
        "SUBS = {\n",
        "    '—': '-',  # em dash -> hyphen\n",
        "    '–': '-',  # en dash -> hyphen\n",
        "    '－': '-',  # fullwidth hyphen-minus -> hyphen\n",
        "    '·': '•',  # middle dot -> bullet (or flip if you prefer)\n",
        "    '﹏': '_', # fullwidth low line alt -> underscore\n",
        "}\n",
        "\n",
        "# Regex for literal \\uXXXX sequences (when strings are double-escaped)\n",
        "_U_ESC_RE = re.compile(r'\\\\u([0-9a-fA-F]{4})')\n",
        "\n",
        "def _decode_u_escapes(s: str) -> str:\n",
        "    # Replace literal \\uXXXX with the actual codepoint\n",
        "    return _U_ESC_RE.sub(lambda m: chr(int(m.group(1), 16)), s)\n",
        "\n",
        "def canonicalize(s: str, normalize_form=\"NFC\") -> str:\n",
        "    o = s\n",
        "    # 1) turn any literal \\uXXXX into real chars (if present)\n",
        "    s = _decode_u_escapes(s)\n",
        "    # 2) Unicode normalize (NFC keeps composed glyphs; NFKC is more aggressive)\n",
        "    s = unicodedata.normalize(normalize_form, s)\n",
        "    # 3) strip zero-width/control-ish characters\n",
        "    s = ''.join(ch for ch in s if ch not in ZERO_WIDTH and not unicodedata.category(ch).startswith('C'))\n",
        "    # 4) apply substitutions\n",
        "    s = ''.join(SUBS.get(ch, ch) for ch in s)\n",
        "\n",
        "    if o != s:\n",
        "        print(f\"Converted escaped sequence '{o}' to '{s}'\")\n",
        "    return s\n",
        "\n",
        "def canonicalize_faces(dct: dict) -> dict:\n",
        "    return {k: canonicalize(v) for k, v in dct.items()}"
      ],
      "metadata": {
        "id": "3jZmLtOjTfgL"
      },
      "id": "3jZmLtOjTfgL",
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Strip out escaped sequences and swap in something that won't blow up my vectorization\n",
        "clean_faces = canonicalize_faces(ascii_faces)\n",
        "\n",
        "# Grab the charset of the\n",
        "face_charset = set()\n",
        "for face in clean_faces.values():\n",
        "    face_charset.update(face)\n",
        "face_charset = ''.join(sorted(face_charset))\n",
        "\n",
        "print(\"Face character set:\", face_charset)  # helpful for debug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybZo3-K_T7yQ",
        "outputId": "b236f96e-7d74-4a9c-f8b8-c1a258a9d765"
      },
      "id": "ybZo3-K_T7yQ",
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted escaped sequence '(⌐■⁠_⁠■)' to '(⌐■_■)'\n",
            "Converted escaped sequence '(－‸ლ)' to '(-‸ლ)'\n",
            "Converted escaped sequence '(－_－メ)' to '(-_-メ)'\n",
            "Face character set:  ()*-./:;<>BOPT[\\]^_ovxz~¬¯°³ºĹʖʘ̯̀́̿͜͡ωд۞ಠงლ‐’•‸‿↼−≦≧⌐━┌┻▀■▨▽◇◕◡☆☞☠☭♥♪✧✿づツノメヮ・彡益／＼＾｡･ﾉﾞﾟ￣\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define some ChatGPT-sourced routines for randomly sampling our cleaned face dict."
      ],
      "metadata": {
        "id": "kmFiskFMdMtC"
      },
      "id": "kmFiskFMdMtC"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random_face():\n",
        "    \"\"\"Return a random ASCII-face from the dictionary.\"\"\"\n",
        "    return random.choice(list(clean_faces.values()))\n",
        "\n",
        "def get_random_nonface(min_len=3, max_len=10):\n",
        "    \"\"\"\n",
        "    Generate a random string of characters drawn only from face_charset,\n",
        "    but arranged in a way that likely doesn’t look like a face.\n",
        "    \"\"\"\n",
        "    length = random.randint(min_len, max_len)\n",
        "    return ''.join(random.choice(face_charset) for _ in range(length))\n",
        "\n",
        "def sample_face(face_prob=0.5):\n",
        "    \"\"\"Sample either a face (positive) or a random non-face (negative).\"\"\"\n",
        "    if random.random() < face_prob:\n",
        "        return get_random_face(), True\n",
        "    else:\n",
        "        return get_random_nonface(), False\n",
        "\n",
        "def generate_dataset(n_samples, face_prob=0.5):\n",
        "    \"\"\"Generate a list of (text, label) pairs.\"\"\"\n",
        "    return [ sample_face(face_prob) for _ in range(n_samples) ]\n"
      ],
      "metadata": {
        "id": "IsuwjDHmVhAB"
      },
      "id": "IsuwjDHmVhAB",
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now randomly select a few faces and non-faces along with their label to validate the strategy. Then emit a dataset-worthy array of same."
      ],
      "metadata": {
        "id": "hoeliXWddY6S"
      },
      "id": "hoeliXWddY6S"
    },
    {
      "cell_type": "code",
      "source": [
        "# Test our dataset generator\n",
        "for _ in range(10):\n",
        "    seq, label = sample_face(face_prob=0.5)\n",
        "    print(f\"{seq} => {'FACE' if label else 'NON-FACE'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmwtRiMHRfEy",
        "outputId": "8d218179-4e9c-4077-e950-75c0724660b8"
      },
      "id": "AmwtRiMHRfEy",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OO▨*･ => NON-FACE\n",
            "(・_・;) => FACE\n",
            "]‐*x_☠▀↼ => NON-FACE\n",
            "(>_> ) => FACE\n",
            "(ಠ_ಠ ┌) => FACE\n",
            "(⌐■_■) => FACE\n",
            "۞’ヮ☭◡≧ => NON-FACE\n",
            "O◕\\◡♪ʘ³✧ => NON-FACE\n",
            "́ง’ => NON-FACE\n",
            "ĹoB]_< => NON-FACE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a dataset of faces and non-faces\n",
        "seqs = []\n",
        "labels = []\n",
        "for _ in range(1000):\n",
        "  seq, label = sample_face(face_prob=0.5)\n",
        "  seqs.append(seq)\n",
        "  labels.append(label)"
      ],
      "metadata": {
        "id": "-GvtEbhjRgvL"
      },
      "id": "-GvtEbhjRgvL",
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we need to get to a fixed-width for our input vector to the model we'll build. Sprinkle some GPT-5 sauce to define functions that map our characters into a relatively compact integer space (avoids super sparse values we'd otherwise get if we used the unicode value) and emit a padded variant of our dataset (fixed sequence length)."
      ],
      "metadata": {
        "id": "Mj_iP2TGdT_-"
      },
      "id": "Mj_iP2TGdT_-"
    },
    {
      "cell_type": "code",
      "source": [
        "def build_global_char_mapping(all_characters):\n",
        "    \"\"\"\n",
        "    Build integer mappings for every unique Unicode character in the dataset.\n",
        "\n",
        "    Parameters:\n",
        "        all_characters (Iterable[str]): A set or list of all unique characters\n",
        "                                        you expect to encounter (faces + non-faces).\n",
        "    Returns:\n",
        "        tuple(dict, dict): (char_to_int, int_to_char)\n",
        "    \"\"\"\n",
        "    # Sort for deterministic ordering (important for reproducibility)\n",
        "    sorted_chars = sorted(all_characters)\n",
        "\n",
        "    # Assign a unique integer ID to each character\n",
        "    char_to_int = {ch: idx for idx, ch in enumerate(sorted_chars)}\n",
        "    int_to_char = {idx: ch for ch, idx in char_to_int.items()}\n",
        "\n",
        "    return char_to_int, int_to_char\n",
        "\n",
        "def encode_strings(strings, char2int):\n",
        "    \"\"\"\n",
        "    Convert a list of strings into integer-based representations\n",
        "    using the provided char2int mapping.\n",
        "    Unknown characters are ignored or mapped to 0 if desired.\n",
        "    Returns a list of lists of integers.\n",
        "    \"\"\"\n",
        "    encoded = []\n",
        "    for s in strings:\n",
        "        encoded.append([char2int.get(ch, 0) for ch in s])\n",
        "    return encoded\n",
        "\n",
        "def random_pad_sequences(encoded_strings, pad_value=0):\n",
        "    \"\"\"\n",
        "    Randomly pad each integer sequence (left or right) so all have the same length.\n",
        "    pad_value is used for padding.\n",
        "    Returns a new list of equal-length sequences.\n",
        "    \"\"\"\n",
        "    # 1. Determine max length\n",
        "    max_len = max(len(seq) for seq in encoded_strings)\n",
        "    padded = []\n",
        "\n",
        "    for seq in encoded_strings:\n",
        "        pad_len = max_len - len(seq)\n",
        "        if pad_len == 0:\n",
        "            padded.append(seq)\n",
        "            continue\n",
        "\n",
        "        # Randomly choose left or right padding\n",
        "        if random.random() < 0.5:\n",
        "            # left pad\n",
        "            new_seq = [pad_value] * pad_len + seq\n",
        "        else:\n",
        "            # right pad\n",
        "            new_seq = seq + [pad_value] * pad_len\n",
        "\n",
        "        padded.append(new_seq)\n",
        "\n",
        "    return padded, max_len"
      ],
      "metadata": {
        "id": "5V1HSjq5Sid_"
      },
      "id": "5V1HSjq5Sid_",
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a mapping and test the encoding to see a string and it's integer value:"
      ],
      "metadata": {
        "id": "Hz9YkTUheNjA"
      },
      "id": "Hz9YkTUheNjA"
    },
    {
      "cell_type": "code",
      "source": [
        "char2int, int2char = build_global_char_mapping(face_charset)\n",
        "\n",
        "test = seqs[1]\n",
        "print(test)\n",
        "encode_strings([test], char2int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_JIQ6s2bAq0",
        "outputId": "b21ef784-74bb-44a6-cf72-1b3ca1a40149"
      },
      "id": "b_JIQ6s2bAq0",
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(>_<;)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 10, 19, 9, 8, 2]]"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can properly encode our strings and pad the result randomly to achieve fixed-width and positional diversity. We'll scale and recast these as floats to prepare for modeling."
      ],
      "metadata": {
        "id": "-s-Bqzb-edNV"
      },
      "id": "-s-Bqzb-edNV"
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = encode_strings(seqs, char2int)\n",
        "padded, seq_len = random_pad_sequences(encoded)"
      ],
      "metadata": {
        "id": "vO62-nL7aIqW"
      },
      "id": "vO62-nL7aIqW",
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(padded[0])/90"
      ],
      "metadata": {
        "id": "pNkMwM16kKIs",
        "outputId": "293533ae-e2ef-49bf-c922-f7bf9d0f39ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "pNkMwM16kKIs",
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.01111111, 0.33333333, 0.06666667,\n",
              "       0.64444444, 0.44444444])"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_length = len(char2int)\n",
        "X = [ np.array(seq) / vocab_length for seq in padded]\n",
        "X = np.array(X)\n",
        "y = labels"
      ],
      "metadata": {
        "id": "D26vq9jre_Ag"
      },
      "id": "D26vq9jre_Ag",
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "p7pfnZbBllTg",
        "outputId": "2f1b31b1-44a8-4254-dea6-d81ea11d3207",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "p7pfnZbBllTg",
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzgjHKqnfAev",
        "outputId": "ce156de9-4771-4958-f691-cd5f4ca5b279"
      },
      "id": "CzgjHKqnfAev",
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01111111, 0.33333333, 0.06666667,\n",
              "        0.64444444, 0.44444444],\n",
              "       [0.01111111, 0.11111111, 0.21111111, 0.1       , 0.08888889,\n",
              "        0.02222222, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.23333333, 0.93333333, 0.64444444, 0.        , 0.6       ,\n",
              "        0.34444444, 0.64444444],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01111111, 0.74444444, 0.21111111,\n",
              "        0.74444444, 0.02222222],\n",
              "       [0.14444444, 0.18888889, 0.2       , 0.36666667, 0.46666667,\n",
              "        0.86666667, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDBE780qfCkQ",
        "outputId": "d82df9f8-8084-4f77-93a1-7664c35eaa53"
      },
      "id": "tDBE780qfCkQ",
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[False, True, False, True, False]"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture"
      ],
      "metadata": {
        "id": "y85A_CpacQXJ"
      },
      "id": "y85A_CpacQXJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now need to build a model that will accept out weird sequence and try to classify it. We opt for a wickedly pared down variant of the transformer."
      ],
      "metadata": {
        "id": "7FUVHNOseqJv"
      },
      "id": "7FUVHNOseqJv"
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "SBmVRdtT34V4"
      },
      "id": "SBmVRdtT34V4",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    A toy torch module for self attention. Informed by Andrej Karpathy's mingpt project\n",
        "    (https://github.com/karpathy/minGPT) and a slightly embarassing conversation with\n",
        "    ChatGPT-5 (https://chatgpt.com/share/690e21fa-e718-8004-860a-45109a95c291)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_dim=10, scale=False):\n",
        "        \"\"\"\n",
        "        Input dimensions are typically sharded across heads in multi-head attention.\n",
        "        We are aiming for simplicity and avoid this, usiing just a single 'head' with\n",
        "        the full input dimension.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.Q = nn.Linear(n_dim, n_dim)\n",
        "        self.K = nn.Linear(n_dim, n_dim)\n",
        "        self.V = nn.Linear(n_dim, n_dim)\n",
        "\n",
        "        self.n_dim = n_dim\n",
        "        self.scale = scale\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        We accept input in the shape of batch, seq length, model dimension.\n",
        "\n",
        "        Note we don't need any linear layers as output because we're only using a single\n",
        "        attention head. If we had more, we would need to map our heads back into the d_model\n",
        "        space with a linear layer.\n",
        "        \"\"\"\n",
        "\n",
        "        # Project our input into the query space (i.e. multiply by the query weights),\n",
        "        # do the same for the key space. Then apply our similarity operation (dot product\n",
        "        # by way of matmul) to yield an attention tensor.\n",
        "        q = self.Q(x)\n",
        "        k = self.K(x)\n",
        "        attn = torch.matmul(q, k.transpose(-2,-1))\n",
        "\n",
        "        # We optionally scale our attention values down to avoid them blasting off and saturating\n",
        "        # the softmax function (thereby destroying gradients during backprop). For tiny models,\n",
        "        # this is probably not an issue and so we allow omission to simplify the model.\n",
        "        if self.scale:\n",
        "            attn = attn / math.sqrt(self.n_dim)\n",
        "\n",
        "        # Now normalize our logits with softmax so we can scale the value vector based on the\n",
        "        # attention we are learning to pay to each respective token\n",
        "        attn = F.softmax(attn, dim=-1)\n",
        "\n",
        "        v = self.V(x)\n",
        "\n",
        "        out = torch.matmul(attn, v)\n",
        "\n",
        "        return out, attn\n"
      ],
      "metadata": {
        "id": "p2rWZzi84FFW"
      },
      "id": "p2rWZzi84FFW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_dim, n_seq):\n",
        "      \"\"\"\n",
        "      Define a model that accepts a sequence and predicts whether it contains a face.\n",
        "      \"\"\"\n",
        "      # Give the model a scratch pad to decompose our characters\n",
        "      self.embedder = nn.Linear(1, n_dim)\n",
        "      self.attn = SelfAttention(n_dim=n_dim, scale=True)\n",
        "      self.fc = nn.Linear(n_dim, 1)\n",
        "      self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, X):\n",
        "      \"\"\"\n",
        "      Do a forward pass through the network, applying attention and emitting a class probability.\n",
        "      We accept a sequence of single values (representing the respeective character), of\n",
        "      shape (batch, seq, 1).\n",
        "      \"\"\"\n",
        "      X = self.embedder(X)\n",
        "      X = self.attn(X)\n",
        "      X = self.fc(X)\n",
        "      X = self.sigmoid(X)\n",
        "\n",
        "      return X"
      ],
      "metadata": {
        "id": "B1vWSfSafGpK"
      },
      "id": "B1vWSfSafGpK",
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "id": "cthtKjHIhtUz"
      },
      "id": "cthtKjHIhtUz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's split up our data and train the model!"
      ],
      "metadata": {
        "id": "bk7q9_AzhvjO"
      },
      "id": "bk7q9_AzhvjO"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "H4nL30GQhmAd"
      },
      "id": "H4nL30GQhmAd",
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FaceClassifier(n_dim=seq_len)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "baN7xKRohgIV",
        "outputId": "85fc4c32-36ea-4131-d174-19381e5fe6d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "id": "baN7xKRohgIV",
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "FaceClassifier.__init__() missing 1 required positional argument: 'n_seq'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1251514565.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFaceClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: FaceClassifier.__init__() missing 1 required positional argument: 'n_seq'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s_bNZNHuiApy"
      },
      "id": "s_bNZNHuiApy",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}